{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7SXpaKwwGe5x"
   },
   "source": [
    "# TM10007 Assignment template -- ECG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and cleaning\n",
    "\n",
    "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "CiDn2Sk-VWqE",
    "outputId": "64224cd2-6054-4b04-a3f6-af8290400dfc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets as ds\n",
    "import seaborn\n",
    "import math\n",
    "import statistics\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro \n",
    "from scipy.stats import lognorm\n",
    "\n",
    "# Classifiers\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn import feature_selection \n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "\n",
    "cwd = os.getcwd() # This fn will return the Current Working Directory\n",
    "\n",
    "zip_path = os.path.join(cwd, 'ecg', 'ecg_data.zip')\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(os.path.join(cwd, 'ecg'))\n",
    "\n",
    "data_path = os.path.join(cwd, 'ecg', 'ecg_data.csv')\n",
    "data = pd.read_csv(data_path, index_col=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring data\n",
    "- How many people have a normal ECG?\n",
    "- How many people have an abnormal ECG?\n",
    "- Is there any missing data?\n",
    "- Are there outliers? \n",
    "- Is the data normally distributed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapiroResult(statistic=nan, pvalue=1.0)\n"
     ]
    }
   ],
   "source": [
    "# split labels from data\n",
    "x = data.loc[:, data.columns != 'label']  #alles behalve label\n",
    "y = data['label']  # labels\n",
    "\n",
    "# normal / abnormal ECGs\n",
    "total_abnormal_ECG = np.count_nonzero(y)  # current dataset has 146 nonzeros\n",
    "total_normal_ECG = y.size -np.count_nonzero(y)  # current dataset has 681 zeros\n",
    "percentage_abnormal = total_abnormal_ECG / (total_abnormal_ECG + total_normal_ECG)*100  # 17.65 %\n",
    "\n",
    "# Missing data\n",
    "x = x.replace(0, np.nan)  # make all zeros to NaN\n",
    "nan_count = x.isna().sum().sum()  # count missing data -> 10500 in our dataset\n",
    "\n",
    "# Outliers\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data\n",
    "- Removing features if there is lot of data missing (replace all for a value)\n",
    "- Removing samples (in this case patients) if there is a lot of data missing\n",
    "- Imputation for generating data to fill us missing values\n",
    "    - Fill with the mean or median of feature.\n",
    "    - Fill with the value from a random other sample.\n",
    "    - Fill with value with highest frequency (good for categorical features).\n",
    "    - Use regression or machine learning to estimate the missing value\n",
    "    - We need to make a choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Column         W       p-value\n",
      "0        0_0  0.493494  2.774571e-43\n",
      "1        0_1  0.362613  0.000000e+00\n",
      "2        0_2  0.423284  2.802597e-45\n",
      "3        0_3  0.383631  0.000000e+00\n",
      "4        0_4  0.415530  1.401298e-45\n",
      "...      ...       ...           ...\n",
      "8995  11_745  0.288316  0.000000e+00\n",
      "8996  11_746  0.219243  0.000000e+00\n",
      "8997  11_747  0.231345  0.000000e+00\n",
      "8998  11_748  0.278828  0.000000e+00\n",
      "8999  11_749  0.182315  0.000000e+00\n",
      "\n",
      "[9000 rows x 3 columns]\n",
      "8.56094515530035e-27\n"
     ]
    }
   ],
   "source": [
    "# Delete missing data when > --% of feature of sample is missing\n",
    "x = x.dropna(axis='columns', how='all') # deletes a feature if all values of a column (so feature) are empty\n",
    "x = x.dropna(axis='rows', how='all') # deletes a patient if all values of a row (so sample) are empty\n",
    "\n",
    "# Missing data to median per feature\n",
    "for column in x.columns:\n",
    "    x[column].fillna(x[column].median(), inplace=True)\n",
    "\n",
    "# Normally distributed\n",
    "stat = []\n",
    "p = []\n",
    "for col in x.columns:\n",
    "    if x[col].dtype == 'float64' or x[col].dtype == 'int64':\n",
    "        s, pv = shapiro(x[col])\n",
    "        stat.append(s)\n",
    "        p.append(pv)\n",
    "    else:\n",
    "        stat.append(None)\n",
    "        p.append(None)\n",
    "\n",
    "# create a new dataframe to store the results\n",
    "results = pd.DataFrame({'Column': x.columns, 'W': stat, 'p-value': p}) \n",
    "mean_p_value = results['p-value'].mean()  # p-value is really small. If p-value is bigger than 0.05, then data is normally distributed. SO its not"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into training and test data\n",
    "- Subset training and test based on ratios\n",
    "- Stratification\n",
    "- Cross-validation?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573    False\n",
      "302     True\n",
      "186    False\n",
      "802    False\n",
      "536    False\n",
      "       ...  \n",
      "519    False\n",
      "156    False\n",
      "665    False\n",
      "809    False\n",
      "419    False\n",
      "Name: label, Length: 620, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "X_train, X_test_DO_NOT_FIT, y_train, y_test_DO_NOT_FIT = model_selection.train_test_split(X, y, test_size=0.25, stratify=y)\n",
    "y_train_ab = y_train==1\n",
    "print(y_train_ab)\n",
    "# X_test_DO_NOT_FIT and y_test_DO_NOT_FIT SHOULD NOT BE USED FOR FITTING\n",
    "\n",
    "# Scale the data to be normal\n",
    "scaler = preprocessing.RobustScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled_DO_NOT_FIT = scaler.transform(X_test_DO_NOT_FIT)\n",
    "\n",
    "# Cross-validation\n",
    "# cv_20fold = model_selection.StratifiedKFold(n_splits=10) --> uit college 1.2_generalization.ipyb\n",
    "\n",
    "# Loop over the folds\n",
    "#for validation_index, test_index in cv_20fold.split(X2, y2):\n",
    "    # Split the data properly\n",
    "#    X_validation = X2[validation_index]\n",
    "#    y_validation = y2[validation_index]\n",
    "    \n",
    "#    X_test = X2[test_index]\n",
    "#    y_test = y2[test_index]\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
