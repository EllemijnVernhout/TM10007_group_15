{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7SXpaKwwGe5x"
   },
   "source": [
    "# TM10007 Assignment template -- ECG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and cleaning\n",
    "\n",
    "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets as ds\n",
    "import seaborn\n",
    "import math\n",
    "import statistics\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets as ds\n",
    "import seaborn\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro \n",
    "from scipy.stats import lognorm\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "# Classifiers\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn import feature_selection \n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "cwd = os.getcwd() # This fn will return the Current Working Directory\n",
    "\n",
    "zip_path = os.path.join(cwd, 'ecg', 'ecg_data.zip')\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(os.path.join(cwd, 'ecg'))\n",
    "\n",
    "data_path = os.path.join(cwd, 'ecg', 'ecg_data.csv')\n",
    "data = pd.read_csv(data_path, index_col=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring data part 1\n",
    "- How many people have a normal ECG?\n",
    "- How many people have an abnormal ECG?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split labels from data\n",
    "x = data.loc[:, data.columns != 'label']  #alles behalve label\n",
    "y = data['label']  # labels\n",
    "\n",
    "# normal / abnormal ECGs\n",
    "total_abnormal_ECG = np.count_nonzero(y)  # current dataset has 146 nonzeros\n",
    "total_normal_ECG = y.size -np.count_nonzero(y)  # current dataset has 681 zeros\n",
    "percentage_abnormal = total_abnormal_ECG / (total_abnormal_ECG + total_normal_ECG)*100  # 17.65 %\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into training and test data\n",
    "- Subset training and test based on ratios\n",
    "- Stratification\n",
    "- Cross-validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test_DO_NOT_FIT, y_train, y_test_DO_NOT_FIT = model_selection.train_test_split(x, y, test_size=0.25, stratify=y)\n",
    "y_train_ab = y_train==1  # waarom maken we hier bools van? ipv 1 en 0 hebben we nu true en false\n",
    "# X_test_DO_NOT_FIT and y_test_DO_NOT_FIT SHOULD NOT BE USED FOR FITTING!!\n",
    "\n",
    "# Scale the data to be normal\n",
    "scaler = preprocessing.RobustScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test_scaled_DO_NOT_FIT = scaler.transform(X_test_DO_NOT_FIT)\n",
    "\n",
    "X_train=pd.DataFrame(X_train)\n",
    "X_test_scaled_DO_NOT_FIT = pd.DataFrame(X_test_scaled_DO_NOT_FIT)\n",
    "\n",
    "# Cross-validation\n",
    "# cv_20fold = model_selection.StratifiedKFold(n_splits=10) --> uit college 1.2_generalization.ipyb\n",
    "\n",
    "# Loop over the folds\n",
    "#for validation_index, test_index in cv_20fold.split(X2, y2):\n",
    "    # Split the data properly\n",
    "#    X_validation = X2[validation_index]\n",
    "#    y_validation = y2[validation_index]\n",
    "    \n",
    "#    X_test = X2[test_index]\n",
    "#    y_test = y2[test_index]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data\n",
    "- Removing features if there is lot of data missing (replace all for a value)\n",
    "- Removing samples (in this case patients) if there is a lot of data missing\n",
    "- Imputation for generating data to fill us missing values -> median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing data\n",
    "X_train = X_train.replace(0, np.nan)  # make all zeros to NaN\n",
    "nan_count = X_train.isna().sum().sum()  # count missing data -> 10500 in our dataset\n",
    "\n",
    "# Delete missing data when > --% of feature of sample is missing\n",
    "X_train = X_train.dropna(axis='columns', how='all') # deletes a feature if all values of a column (so feature) are empty\n",
    "X_train = X_train.dropna(axis='rows', how='all') # deletes a patient if all values of a row (so sample) are empty\n",
    "\n",
    "# Missing data to median per feature\n",
    "for column in X_train.columns:\n",
    "    X_train[column].fillna(X_train[column].median(), inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring data part 2\n",
    "- Is the data normally distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[213], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m stat \u001b[39m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m p \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m X_train\u001b[39m.\u001b[39;49mcolumns:\n\u001b[0;32m      5\u001b[0m     \u001b[39mif\u001b[39;00m X_train[col]\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mfloat64\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m X_train[col]\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mint64\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m      6\u001b[0m         s, pv \u001b[39m=\u001b[39m shapiro(X_train[col])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# Normally distributed\n",
    "stat = []\n",
    "p = []\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].dtype == 'float64' or X_train[col].dtype == 'int64':\n",
    "        s, pv = shapiro(X_train[col])\n",
    "        stat.append(s)\n",
    "        p.append(pv)\n",
    "    else:\n",
    "        stat.append(None)\n",
    "        p.append(None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers\n",
    "- Detect outliers using Z-score since data is not nornally distributed\n",
    "- Replace outliers by the median of that feature\n",
    "- Print -> check wether the outliers are changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe to store the results\n",
    "results = pd.DataFrame({'Column': X_train.columns, 'W': stat, 'p-value': p}) \n",
    "mean_p_value = results['p-value'].mean()  # p-value is really small. If p-value is bigger than 0.05, then data is normally distributed. SO its not\n",
    "median_p_value = results['p-value'].median()  # p-value is really small. If p-value is bigger than 0.05, then data is normally distributed. SO its not\n",
    "\n",
    "# Outliers: Tukey's fence \n",
    "k=3\n",
    "fences=pd.DataFrame()\n",
    "outliers = pd.DataFrame(False, index=X_train.index, columns=X_train.columns) # create an empty DataFrame for outliers\n",
    "\n",
    "for col in X_train.columns:\n",
    "    q1, q3 = np.percentile(X_train[col], [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower_fence = q1 - k*iqr\n",
    "    upper_fence = q3 + k*iqr\n",
    "    fences[col]=[lower_fence, upper_fence]\n",
    "    for row in X_train.index:\n",
    "        if X_train.loc[row, col] < lower_fence or X_train.loc[row, col] > upper_fence:\n",
    "            outliers.loc[row, col] = True # mark the place as an outlier\n",
    "\n",
    "row_count = (outliers == True).sum(axis=1)\n",
    "col_count = (outliers == True).sum(axis=0)\n",
    "total_count = row_count.sum() + col_count.sum()\n",
    "print(f'The total outliers in dataset x is {total_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of x to modify\n",
    "new_x = X_train.copy()\n",
    "\n",
    "# replace outliers with median of x by column\n",
    "for col in outliers.columns:\n",
    "    median = X_train.loc[outliers[col] == False, col].median() # median of column where outlier is False\n",
    "    new_x.loc[outliers[col], col] = median # replace outliers with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check wether there are still outliers or not\n",
    "k=3\n",
    "fences=pd.DataFrame()\n",
    "outliers = pd.DataFrame(False, index=X_train.index, columns=X_train.columns) # create an empty DataFrame for outliers\n",
    "\n",
    "for col in new_x.columns:\n",
    "    q1, q3 = np.percentile(X_train[col], [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower_fence = q1 - k*iqr\n",
    "    upper_fence = q3 + k*iqr\n",
    "    fences[col]=[lower_fence, upper_fence]\n",
    "    for row in new_x.index:\n",
    "        if new_x.loc[row, col] < lower_fence or new_x.loc[row, col] > upper_fence:\n",
    "            outliers.loc[row, col] = True # mark the place as an outlier\n",
    "\n",
    "row_count = (outliers == True).sum(axis=1)\n",
    "col_count = (outliers == True).sum(axis=0)\n",
    "total_count = row_count.sum() + col_count.sum()\n",
    "\n",
    "print(f'total outliers of the filtered x is {total_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the x_train to the new_x\n",
    "X_train = new_x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection:\n",
    "- Remove features with zero variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(620, 9000)\n"
     ]
    }
   ],
   "source": [
    "sel_vt = VarianceThreshold(threshold=0.0)\n",
    "X_vt = sel_vt.fit_transform(X_train, y_train)\n",
    "print(X_vt.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA\n",
    "- How many principal components? (n=2/3) --> to make plots visual\n",
    "- Scree plot to determine amount of features to use?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620\n",
      "620\n",
      "620\n"
     ]
    }
   ],
   "source": [
    "# Reduce the number of features with PCA.\n",
    "n_samples = X_train.shape[0]\n",
    "n_features = X_train.shape[1]\n",
    "n_features = min(n_samples, n_features)\n",
    "\n",
    "pca = PCA(n_components=n_features)            \n",
    "X_train = pca.fit_transform(X_train)\n",
    "\n",
    "print(n_samples)\n",
    "print(n_features)\n",
    "print(pca.n_components_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# selectKbest features \n",
    "sel_kb = SelectKBest(f_classif, k='all')        # we trainen selector wel met 620 best en daarna pakken we pas de p_waarden --> kan dat wel?\n",
    "sel_kb.fit(X_train, y_train)                         # is het dan, omdat we alleen 'fit' doen en niet 'fit_transform' dat de k niet uitmaakt, omdat we X_train niet transformen, maar de 'empirical variances of X' nemen\n",
    "p_values = sel_kb.pvalues_\n",
    "\n",
    "# plot p-values of all features\n",
    "X_indices = np.arange(X_train.shape[-1])\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.bar(X_indices - 0.05, p_values, width=1)\n",
    "plt.axhline(y=0.05, color='r', linestyle='-')\n",
    "plt.title(\"Feature univariate score\")\n",
    "plt.xlabel(\"Feature number\")\n",
    "plt.ylabel('p_values of all features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28)\n",
      "(620, 28)\n"
     ]
    }
   ],
   "source": [
    "# select features with p_value =< 0.05\n",
    "features_selected = np.array(np.where(p_values <= 0.05))\n",
    "print(features_selected.shape)\n",
    "\n",
    "# select significant features in training set\n",
    "X_train = X_train[:,features_selected[0,:]]\n",
    "print(X_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to make 2D-colorplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def colorplot(clf, ax, x, y, h=100, precomputer=None):\n",
    "#     '''\n",
    "#     Overlay the decision areas as colors in an axes.\n",
    "    \n",
    "#     Input:\n",
    "#         clf: trained classifier\n",
    "#         ax: axis to overlay color mesh on\n",
    "#         x: feature on x-axis\n",
    "#         y: feature on y-axis\n",
    "#         h(optional): steps in the mesh\n",
    "#     '''\n",
    "#     # Create a meshgrid the size of the axis\n",
    "#     xstep = (x.max() - x.min() ) / 20.0\n",
    "#     ystep = (y.max() - y.min() ) / 20.0\n",
    "#     x_min, x_max = x.min() - xstep, x.max() + xstep\n",
    "#     y_min, y_max = y.min() - ystep, y.max() + ystep\n",
    "#     h = max((x_max - x_min, y_max - y_min))/h\n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "#                          np.arange(y_min, y_max, h))\n",
    "\n",
    "#     features = np.c_[xx.ravel(), yy.ravel()]\n",
    "#     if precomputer is not None:\n",
    "#         if type(precomputer) is RBFSampler:\n",
    "#             features = precomputer.transform(features)\n",
    "#         elif precomputer is rbf_kernel:\n",
    "#             features = rbf_kernel(features, X)\n",
    "            \n",
    "#     # Plot the decision boundary. For that, we will assign a color to each\n",
    "#     # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "#     if hasattr(clf, \"decision_function\"):\n",
    "#         Z = clf.decision_function(features)\n",
    "#     else:\n",
    "#         Z = clf.predict_proba(features)\n",
    "#     if len(Z.shape) > 1:\n",
    "#         Z = Z[:, 1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying out some basic classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 620 points : 66\n",
      "<class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>\n",
      "Acc:0.8935483870967742\n",
      "AUC:0.8896569058690461\n",
      "F1:0.6162790697674418\n",
      "precision:0.8412698412698413\n",
      "recall:0.48623853211009177\n"
     ]
    }
   ],
   "source": [
    "# fig = plt.figure(figsize=(8, 8))\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax.set_title(\"Two informative features, one cluster per class\",\n",
    "#              fontsize='small')\n",
    "# ax.scatter(X_train[:, 0], X_train[:, 1], marker='o', c=y_train,\n",
    "#            s=25, edgecolor='k', cmap=plt.cm.Paired)\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_train)\n",
    "# colorplot(clf, ax, X_train[:, 0], X_train[:, 1])\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_train.shape[0], (y_train != y_pred).sum()))\n",
    "\n",
    "\n",
    "y_pred=clf.predict(X_train)\n",
    "\n",
    "if hasattr(clf, 'predict_proba'):\n",
    "    # The first column gives the probability for class = 0, so we take\n",
    "    # the second which gives the probability class = 1:\n",
    "    y_score = clf.predict_proba(X_train)[:, 1]\n",
    "else:\n",
    "     y_score = y_pred\n",
    "\n",
    "auc = metrics.roc_auc_score(y_train, y_score)\n",
    "accuracy=metrics.accuracy_score(y_train, y_pred)\n",
    "F1=metrics.f1_score(y_train, y_pred)\n",
    "precision=metrics.precision_score(y_train, y_pred)\n",
    "recall=metrics.recall_score(y_train, y_pred)\n",
    "# accuracy, AUC, f1score, precision, recall\n",
    "print(type(clf))\n",
    "print('Acc:' +str(accuracy))\n",
    "print('AUC:' +str(auc))\n",
    "print('F1:' +str(F1))\n",
    "print('precision:' +str(precision))\n",
    "print('recall:' +str(recall))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Neirest Neighbour classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8564516129032258\n"
     ]
    }
   ],
   "source": [
    "k_list = [1, 3, 7]\n",
    "from sklearn import neighbors\n",
    "\n",
    "for k in k_list:\n",
    "    clf_knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    clf_knn.fit(X_train, y_train)\n",
    "\n",
    "    # Test the classifier on the training data and plot\n",
    "    score_train = clf_knn.score(X_train, y_train)\n",
    "\n",
    "    # Test the classifier on the test data and plot\n",
    "    # score_test = clf_knn.score(X_test_scaled_DO_NOT_FIT,y_test_DO_NOT_FIT)\n",
    "\n",
    "# print(f'test score os {score_test}')\n",
    "print(score_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Support Vector Machines* \n",
    "Altough Support Vector Machines are quite intuitive and easy to use, they have quite a lot of hyperparameters. One general and highly important parameter is the slack C, which defaults to 1.0 in scikit learn. The SVM in scikit-learn contains defaults for the linear, polynomial and radial basis function kernels, and has options for their specific hyperparameters. However, SVMs also accept manually constructed and precomputed kernels.\n",
    "\n",
    "*KNeighbours Classifiers*\n",
    "*Random forest*\n",
    "*Kernels*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\base.py:402: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 9000 features, but KNeighborsClassifier is expecting 28 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[212], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m clf \u001b[39min\u001b[39;00m clsfs:\n\u001b[0;32m     11\u001b[0m     clf\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m---> 12\u001b[0m     y_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mpredict(x)\n\u001b[0;32m     13\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMisclassified: %d / %d % \u001b[39m\u001b[39m{\u001b[39;00m((y\u001b[39m \u001b[39m\u001b[39m!=\u001b[39m\u001b[39m \u001b[39my_pred)\u001b[39m.\u001b[39msum(),\u001b[39m \u001b[39mx\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m )\n",
      "File \u001b[1;32mc:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:234\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[0;32m    220\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39m    Class labels for each data sample.\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    232\u001b[0m     \u001b[39m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[39m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     neigh_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkneighbors(X, return_distance\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    235\u001b[0m     neigh_dist \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py:806\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    804\u001b[0m         X \u001b[39m=\u001b[39m _check_precomputed(X)\n\u001b[0;32m    805\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 806\u001b[0m         X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    808\u001b[0m n_samples_fit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_fit_\n\u001b[0;32m    809\u001b[0m \u001b[39mif\u001b[39;00m n_neighbors \u001b[39m>\u001b[39m n_samples_fit:\n",
      "File \u001b[1;32mc:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\base.py:558\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    555\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    557\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 558\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    560\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\base.py:359\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 359\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    360\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    361\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    362\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 9000 features, but KNeighborsClassifier is expecting 28 features as input."
     ]
    }
   ],
   "source": [
    "# Construct classifiers\n",
    "svmlin = SVC(kernel='linear', gamma='scale')\n",
    "svmrbf = SVC(kernel='rbf', gamma='scale')\n",
    "svmpoly = SVC(kernel='poly', degree=3, gamma='scale')\n",
    "\n",
    "clsfs = [KNeighborsClassifier(), RandomForestClassifier(), svmlin, svmpoly, svmrbf]\n",
    "\n",
    "\n",
    "\n",
    "for clf in clsfs:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(x)\n",
    "    print(f'Misclassified: %d / %d % {((y != y_pred).sum(), x.shape[0])}' )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "8639542d0d5c4a86b9e021f83681c733ad8933a32667505318364d619e2658a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
