{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["9m3JUs7lp_aW","uFKm6roUqaTn","XCEIm_wbqDSS","dDh5p1aaqG9o","UkerFxQDqkkw","gwramotsxmFR","fs2JpG9Zy3ib","kf25y4FtzYdl","-bWqOArv0Etj","GqGugMuY06P8","hZ3xrwmn1mdX","t5O52Uz12l3A","4lTgYkJgygiz"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Clone github and import modules"],"metadata":{"id":"9m3JUs7lp_aW"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sb2MDd5rpIzI","executionInfo":{"status":"ok","timestamp":1682084173181,"user_tz":-120,"elapsed":4308,"user":{"displayName":"Julia Binder","userId":"04445038020140268015"}},"outputId":"982ed3a6-c6b3-43f0-b868-3d85d231c995"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'tm10007_ml' already exists and is not an empty directory.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.9/dist-packages (0.0.post4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.22.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.7.1)\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.9/dist-packages (0.10.1)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.9/dist-packages (0.13.5)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (5.12.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (8.4.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.0.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.0)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.10.1)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (3.1.0)\n","Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.9/dist-packages (from statsmodels) (0.5.3)\n","Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.9/dist-packages (from statsmodels) (1.5.3)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.25->statsmodels) (2022.7.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n"]}],"source":["# Clone github and import modules\n","!git clone https://github.com/jveenland/tm10007_ml.git\n","\n","! pip install sklearn numpy matplotlib imbalanced-learn statsmodels\n","\n","import zipfile\n","import statsmodels\n","import warnings\n","import statistics\n","import seaborn as sns\n","import pandas as pd\n","import numpy as np \n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_recall_curve, average_precision_score, f1_score\n","from sklearn.compose import TransformedTargetRegressor\n","from scipy.stats import shapiro, lognorm, randint\n","from scipy.spatial.distance import cdist\n","from sklearn.model_selection import StratifiedShuffleSplit, learning_curve, GridSearchCV, StratifiedKFold, cross_val_score, KFold, train_test_split, RandomizedSearchCV, validation_curve \n","from sklearn import preprocessing\n","from sklearn.preprocessing import RobustScaler, StandardScaler\n","from imblearn.over_sampling import RandomOverSampler\n","from sklearn import datasets as ds, model_selection, metrics, neighbors\n","from sklearn.linear_model import Lasso\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import f1_score\n","from sklearn.linear_model import LinearRegression\n","from statsmodels.stats.multitest import multipletests\n","from sklearn.exceptions import ConvergenceWarning\n","from sklearn.metrics import make_scorer, f1_score\n","from sklearn.metrics import classification_report\n","\n","# Classifiers\n","from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif, SelectFromModel\n","from sklearn.decomposition import PCA\n","from sklearn.svm import SVC, LinearSVC\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n","from sklearn.naive_bayes import GaussianNB"]},{"cell_type":"markdown","source":["##Defining functions"],"metadata":{"id":"uFKm6roUqaTn"}},{"cell_type":"markdown","source":["Missing data\n"],"metadata":{"id":"KbvCkNP4qoLR"}},{"cell_type":"code","source":["def missing_data(X_design):\n","  # Missing data\n","  nan_count = X_design.isna().sum().sum()  # count missing data -> 0 in our dataset\n","\n","  # Delete missing data when > 50% of feature or sample is missing\n","  X_design = X_design.dropna(axis='columns', how='all') # deletes a feature if all values of a column (so feature) are empty\n","  X_design = X_design.dropna(axis='rows', how='all') # deletes a patient if all values of a row (so sample) are empty\n","  \n","  #threshold = len(X_design.columns) // 2\n","  #X_design = X_design.dropna(axis='columns', thresh=threshold) # deletes a feature if 50% values of a column (so feature) are empty\n","  #X_design = X_design.dropna(axis='rows', thresh=threshold) # deletes a patient if 50% values of a row (so sample) are empty\n","\n","  # Missing data to median per feature\n","  for column in X_design.columns:\n","      X_design[column].fillna(X_design[column].median(), inplace=True)\n","  return X_design\n","\n","def missing_data_zero_check(X_design):\n","  \"\"\"This function does the same as missing_data, but also corrects for zeros, assuming zeros are missing data\"\"\"\n","  # Missing data\n","  X_design = X_design.replace(0, np.nan)  # make all zeros to NaN\n","  nan_count = X_design.isna().sum().sum()  # count missing data -> 10500 in our dataset\n","\n","  # Delete missing data when > 50% of feature or sample is missing\n","  X_design = X_design.dropna(axis='columns', how='all') # deletes a feature if all values of a column (so feature) are empty\n","  X_design = X_design.dropna(axis='rows', how='all') # deletes a patient if all values of a row (so sample) are empty\n","  #threshold = len(X_design.columns) // 2\n","  #X_design = X_design.dropna(axis='columns', thresh=threshold) # deletes a feature if 50% values of a column (so feature) are empty\n","  #X_design = X_design.dropna(axis='rows', thresh=threshold) # deletes a patient if 50% values of a row (so sample) are empty\n","\n","  # Missing data to median per feature\n","  for column in X_design.columns:\n","      X_design[column].fillna(X_design[column].median(), inplace=True)\n","  return X_design"],"metadata":{"id":"mK5Rl9nVqbuq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Outliers"],"metadata":{"id":"zaAuqjRVrBJG"}},{"cell_type":"code","source":["def removing_outliers(X_design):\n","    # supress performance warning\n","    warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n","\n","    # Outliers: Tukey's fence \n","    k=3\n","    fences=pd.DataFrame()\n","    outliers = pd.DataFrame(False, index=X_design.index, columns=X_design.columns) # create an empty DataFrame for outliers\n","\n","    for col in X_design.columns:\n","        q1, q3 = np.percentile(X_design[col], [25, 75])\n","        iqr = q3 - q1\n","        lower_fence = q1 - k*iqr\n","        upper_fence = q3 + k*iqr\n","        fences[col]=[lower_fence, upper_fence]\n","        for row in X_design.index:\n","            if X_design.loc[row, col] < lower_fence or X_design.loc[row, col] > upper_fence:\n","                outliers.loc[row, col] = True # mark the place as an outlier\n","\n","    row_count = (outliers == True).sum(axis=1)\n","    col_count = (outliers == True).sum(axis=0)\n","    total_count = row_count.sum() + col_count.sum()\n","    print(f'The total number of outliers in dataset x is {total_count}')\n","\n","    # create a copy of x to modify\n","    new_x = X_design.copy()\n","\n","    #replace outliers with maximum or minimun interquartile range of x by column\n","    for col in outliers.columns:\n","        q3 = X_design.loc[outliers[col] == False, col].quantile(0.75) # 3rd quartile of column where outlier is False\n","        q1 = X_design.loc[outliers[col] == False, col].quantile(0.25) # 1st quartile of column where outlier is False\n","        iqr = q3 - q1 # interquartile range of column where outlier is False\n","        lower_fence = q1 - k*iqr\n","        upper_fence = q3 + k*iqr\n","        new_x.loc[outliers[col] & (new_x[col] > upper_fence), col] = upper_fence # replace outliers with upper fence\n","        new_x.loc[outliers[col] & (new_x[col] < lower_fence), col] = lower_fence # replace outliers with lower fence\n","\n","        X_design = new_x.copy()\n","    return X_design"],"metadata":{"id":"H3L11MYVrCBk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For learning curves: PCA+univariate and LASSO"],"metadata":{"id":"NNNHgswNtVVC"}},{"cell_type":"code","source":["def PCA_univariate(X_train, y_train):\n","    #Remove features with zero variance\n","    sel_vt = VarianceThreshold(threshold=0.0)\n","    X_vt = sel_vt.fit_transform(X_train, y_train)\n","    \n","    #PCA\n","    n_samples = X_train.shape[0]\n","    n_features = X_train.shape[1]\n","    n_features = min(n_samples, n_features)\n","\n","    pca = PCA(n_components=n_features)            \n","    X_train = pca.fit_transform(X_train)\n","\n","    #Univariate\n","    sel_kb = SelectKBest(f_classif, k='all')\n","    sel_kb.fit(X_train, y_train)\n","    p_values = sel_kb.pvalues_\n","\n","    reject_fdr, pvals_fdr, _, _ = multipletests(pvals=p_values, alpha=0.05, method='fdr_bh')\n","    features_selected=np.array(np.where(reject_fdr)[0])\n","    print(features_selected.shape)\n","    X_train = X_train[:,features_selected]\n","\n","    return X_train\n","\n","def LASSO_feature(X_train_lasso, y_train):\n","    # Define the Lasso model\n","    lasso = Lasso()\n","\n","    # Grid search\n","    alphas = np.logspace(-5, 1, 100)  # Define the grid of alpha values to search over\n","    grid_search = GridSearchCV(lasso, param_grid={'alpha': alphas}, cv=5)\n","    grid_search.fit(X_train_lasso, y_train)\n","    best_alpha = grid_search.best_params_['alpha']\n","\n","    # Create a new Lasso model using the best alpha value\n","    lasso = Lasso(alpha=best_alpha)\n","    lasso.fit(X_train_lasso, y_train)\n","\n","    # Get the coefficients of the Lasso model, find them and define the new X_train with less features\n","    coef = lasso.coef_\n","    selected_features = np.where(coef != 0)[0]\n","    X_train_lasso = X_train_lasso[selected_features]\n","\n","    return X_train_lasso\n","\n","def plot_learning_curve(estimator, title, X, y, axes, ylim=None, cv=None,\n","                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n","  axes.set_title(title)\n","  if ylim is not None:\n","      axes.set_ylim(*ylim)\n","  axes.set_xlabel(\"Training examples\")\n","  axes.set_ylabel(\"Score\")\n","  \n","  scorer = make_scorer(f1_score)\n","  \n","  train_sizes, train_scores, test_scores  = \\\n","    learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n","                       train_sizes=train_sizes, scoring=scorer)\n","  train_scores_mean = np.mean(train_scores, axis=1)\n","  train_scores_std = np.std(train_scores, axis=1)\n","  test_scores_mean = np.mean(test_scores, axis=1)\n","  test_scores_std = np.std(test_scores, axis=1)\n","    \n","  # Plot learning curve\n","  axes.grid()\n","  axes.fill_between(train_sizes, train_scores_mean - train_scores_std,\n","                         train_scores_mean + train_scores_std, alpha=0.1,\n","                         color=\"r\")\n","  axes.fill_between(train_sizes, test_scores_mean - test_scores_std,\n","                         test_scores_mean + test_scores_std, alpha=0.1,\n","                         color=\"g\")\n","  axes.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n","                 label=\"Training score\")\n","  axes.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n","                 label=\"Cross-validation score\")\n","  axes.legend(loc=\"best\")\n","  \n","  return plt"],"metadata":{"id":"Pr3Be8Mita-p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load data"],"metadata":{"id":"XCEIm_wbqDSS"}},{"cell_type":"code","source":["with zipfile.ZipFile('/content/tm10007_ml/ecg/ecg_data.zip', 'r') as zip_ref:\n","    zip_ref.extractall('/content/tm10007_ml/ecg')\n","\n","data = pd.read_csv('/content/tm10007_ml/ecg/ecg_data.csv', index_col=0)"],"metadata":{"id":"U0Zgo9L8qC87"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Explore data"],"metadata":{"id":"dDh5p1aaqG9o"}},{"cell_type":"code","source":["print(f'The number of samples: {len(data.index)}')\n","print(f'The number of columns: {len(data.columns)}')\n","\n","X = data.loc[:, data.columns != 'label']  #samples and features\n","y = data['label']  # labels\n","\n","# normal / abnormal ECGs\n","total_abnormal_ECG = np.count_nonzero(y) \n","total_normal_ECG = y.size -np.count_nonzero(y) \n","percentage_abnormal = total_abnormal_ECG / (total_abnormal_ECG + total_normal_ECG)*100\n","\n","print(f'{total_abnormal_ECG} people have an abnormal ECG')\n","print(f'{total_normal_ECG} people have a normal ECG')\n","print(f'The percentage of abnormal ECGs in this dataset is {percentage_abnormal} %')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VnHeWuqWqM71","executionInfo":{"status":"ok","timestamp":1682091349989,"user_tz":-120,"elapsed":257,"user":{"displayName":"Julia Binder","userId":"04445038020140268015"}},"outputId":"1c17ff86-4e7a-4931-b58f-d1ed667c3e12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The number of samples: 827\n","The number of columns: 9001\n","9 people have an abnormal ECG\n","41 people have a normal ECG\n","The percentage of abnormal ECGs in this dataset is 18.0 %\n"]}]},{"cell_type":"markdown","source":["## Learning curves\n","The learning curves are commented, but if interested, you can uncomment and see how the curves look like. "],"metadata":{"id":"UkerFxQDqkkw"}},{"cell_type":"markdown","source":["Preperation of data"],"metadata":{"id":"2-T2yJVntgGf"}},{"cell_type":"code","source":["# # create X_train\n","# X_train, X_test_DO_NOT_FIT, y_train, y_test_DO_NOT_FIT = model_selection.train_test_split(X, y, test_size=0.1, stratify=y)\n","\n","# # Balance data\n","# ros = RandomOverSampler(sampling_strategy='minority')\n","# X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n","# X_train = X_resampled\n","# y_train = y_resampled\n","\n","# # Scale the data to be normal\n","# scaler = preprocessing.RobustScaler()\n","# scaler.fit(X_train)\n","# X_train = scaler.transform(X_train)\n","# X_train=pd.DataFrame(X_train)\n","\n","# # Create X_train for PCA+univariate and for LASSO\n","# X_train = X_train.copy()\n","# X_train_lasso = X_train.copy()\n","\n","# clsfs_all = [neighbors.KNeighborsClassifier(n_neighbors=1), \n","#          neighbors.KNeighborsClassifier(n_neighbors=5), \n","#          neighbors.KNeighborsClassifier(n_neighbors=20), \n","#          RandomForestClassifier(n_estimators=1, random_state=42),\n","#          RandomForestClassifier(n_estimators=5, random_state=42),\n","#          RandomForestClassifier(n_estimators=200, random_state=42),\n","#          SVC(kernel='rbf', C=10, gamma=0.1),\n","#          SVC(kernel='linear', C=10, gamma=0.1),\n","#          SVC(kernel='poly', C=10, gamma=0.1),\n","#          SVC(kernel='sigmoid', C=10, gamma=0.1),\n","#          GaussianNB(),\n","#          LinearRegression(),\n","#          QuadraticDiscriminantAnalysis()\n","#          ]\n"],"metadata":{"id":"p0jV-RsvqkWR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Learning curves for PCA+univariate"],"metadata":{"id":"Ggz5rrlXtj5c"}},{"cell_type":"code","source":["# X_train=PCA_univariate(X_train,y_train)\n","\n","# num=0\n","# fig = plt.figure(figsize=(24,8*len(clsfs_all)))\n","\n","# # Create a cross-validation object\n","# cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=0)\n","\n","# # Now use the classifiers on all datasets\n","# for clf in clsfs_all:\n","#     title = str(type(clf))\n","#     ax = fig.add_subplot(7, 3, num + 1)\n","#     plot_learning_curve(clf, title, X_train, y_train, ax, ylim=(0.3, 1.01), cv=cv)\n","#     num += 1"],"metadata":{"id":"NTE4vtFstm9i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Regularization for PCA+ univariate and their new learning curves"],"metadata":{"id":"LrM9BRp2t30t"}},{"cell_type":"code","source":["# # Define the Lasso model\n","# lasso2 = Lasso()\n","# # Define the grid of alpha values to search over\n","# alphas2 = np.logspace(-5, 1, 100)\n","# # Define the grid search\n","# grid_search2 = GridSearchCV(lasso2, param_grid={'alpha': alphas2}, cv=5)\n","# # Fit the grid search to your training data\n","# grid_search2.fit(X_train, y_train)\n","# # Get the best alpha value from the grid search\n","# best_alpha2 = grid_search2.best_params_['alpha']\n","# # Create a new Lasso model using the best alpha value\n","# lasso2 = Lasso(alpha=best_alpha2)\n","# # Fit the Lasso model to your training data\n","# lasso2.fit(X_train, y_train)\n","# # Get the coefficients of the Lasso model\n","# coef2 = lasso2.coef_\n","# # Get the indices of the selected features\n","# selected_features2 = np.where(coef2 != 0)[0]\n","# #X_train_regularization = X_train[selected_features2]\n","# #X_train_regularization = X_train[:,selected_features2]\n","# X_train_regularization = X_train[:,selected_features2[:]]\n","\n","# clsfs_regularization = [SVC(kernel='rbf', C=10, gamma=0.1),\n","#          SVC(kernel='poly', C=10, gamma=0.1),\n","#          RandomForestClassifier(n_estimators=5, random_state=42),\n","#          RandomForestClassifier(n_estimators=200, random_state=42)]\n","\n","# num=0\n","# fig = plt.figure(figsize=(24,8*len(clsfs_regularization)))\n","\n","# # Create a cross-validation object\n","# cv = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n","\n","# # Now use the classifiers on all datasets\n","# for clf in clsfs_regularization:\n","#     title = str(type(clf))\n","#     ax = fig.add_subplot(7, 3, num + 1)\n","#     plot_learning_curve(clf, title, X_train_regularization, y_train, ax, ylim=(0.3, 1.01), cv=cv)\n","#     num += 1"],"metadata":{"id":"SzmTwM50t8Xj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Learning curves for LASSO"],"metadata":{"id":"DOry0Zc4uHzy"}},{"cell_type":"code","source":["# num=0\n","# fig = plt.figure(figsize=(24,8*len(clsfs_all)))\n","\n","# X_train_lasso=LASSO_feature(X_train_lasso,y_train)\n","\n","# # Create a cross-validation object\n","# cv = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n","\n","# # Now use the classifiers on all datasets\n","# for clf in clsfs_all:\n","#     title = str(type(clf))\n","#     ax = fig.add_subplot(7, 3, num + 1)\n","#     plot_learning_curve(clf, title, X_train_lasso, y_train, ax, ylim=(0.3, 1.01), cv=cv)\n","#     num += 1"],"metadata":{"id":"MWIKRIhouJSM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Pipeline *1*: PCA + univariate -> Gaussian Naive Bayes"],"metadata":{"id":"gwramotsxmFR"}},{"cell_type":"code","source":["# Define outer and inner cross validation\n","outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42) \n","inner_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42) \n","\n","#Create empty arrays (for results)\n","f1_design_1_before = []\n","f1_test_1_before = []\n","f1_design_1_after = []\n","f1_test_1_after = []\n","results_1 = pd.DataFrame()\n","best_pipe_1 = []\n","best_hp_1_before = pd.DataFrame()\n","best_hp_1 = pd.DataFrame()\n","y_test_1_all = []\n","y_pred_1_all = []\n","\n","for design_index, test_index in outer_cv.split(X, y): \n","    X_design = X.transpose()[design_index]\n","    X_design = X_design.transpose()\n","    y_design = y[design_index]\n","    \n","    X_test = X.transpose()[test_index]\n","    X_test = X_test.transpose()\n","    y_test_1 = y[test_index].tolist()\n","    y_test_1_all.append(y_test_1)\n","    \n","    # remove outliers\n","    X_design = removing_outliers(X_design)\n","    X_test = removing_outliers(X_test)\n","\n","    # Correct missing data\n","    X_design = missing_data(X_design)\n","    X_test = missing_data(X_test)\n","\n","    # balance the classes, so design set consists of 50% normal and 50% abnormal ECG's\n","    ros = RandomOverSampler(sampling_strategy='minority')\n","    X_resampled, y_resampled = ros.fit_resample(X_design, y_design)\n","    X_design = X_resampled\n","    y_design = y_resampled   \n","\n","    print(f'shape after balancing {X_design.shape}')\n","    \n","    # Define pipeline 1\n","    pipeline_1a = Pipeline([\n","        ('scaler', RobustScaler()),\n","        ('var_threshold', VarianceThreshold(threshold=0.0)),\n","        ('pca', PCA(n_components=0.5)),\n","    ])\n","\n","    param_grid_1a = {\n","        'pca__n_components': [0.5],#,0.75, 0.9, 0.95, 0.99],\n","        }\n","\n","    # Perform grid search with inner cross-validation, part 1\n","    rand_search_1a = RandomizedSearchCV(pipeline_1a, param_distributions=param_grid_1a, n_iter=10, cv=inner_cv, scoring='f1', n_jobs=-1) #klopt n__iter\n","    rand_search_1a.fit(X_design, y_design) # klopt dit fit_transform?\n","    X_design = rand_search_1a.best_estimator_.transform(X_design)\n","    X_test = rand_search_1a.best_estimator_.transform(X_test)\n","    \n","    # Access and store the best set of hyperparameters of each outer-CV loop in a DataFrame\n","    best_hp_1_before = best_hp_1_before.append(rand_search_1a.best_params_,ignore_index=True)\n","    print(best_hp_1_before)\n","    print(f'shape of X_design after pca {X_design.shape}')\n","\n","    sel_kb = SelectKBest(f_classif, k='all')\n","    sel_kb.fit(X_design, y_design)\n","    p_values = sel_kb.pvalues_\n","\n","    reject_fdr, pvals_fdr, _, _ = multipletests(pvals=p_values, alpha=0.05, method='fdr_bh')\n","    features_selected=np.array(np.where(reject_fdr)[0])\n","    print(f'size of features selected{features_selected.shape}')\n","    X_design = X_design[:,features_selected]\n","    X_test = X_test[:,features_selected]\n","    \n","    # pipeline 1b\n","    pipeline_1b = Pipeline([\n","        ('clf', GaussianNB())\n","    ])\n","\n","    # Define scores BEFORE hyperparameter tuning\n","    pipeline_1b.fit(X_design, y_design)\n"," \n","    y_pred_design_1 = pipeline_1b.predict(X_design)\n","    f1_design_1_bef = f1_score(y_design, y_pred_design_1)\n","    f1_design_1_before.append(f1_design_1_bef)\n","\n","    y_pred_test_1_before = pipeline_1b.predict(X_test)\n","    f1_test_1_bef = f1_score(y_test_1, y_pred_test_1_before)\n","    f1_test_1_before.append(f1_test_1_bef)\n","\n","    # Define hyperparameters of pipeline 1\n","    param_grid_1b = {\n","    'clf__var_smoothing': np.logspace(0,-9, num=100),\n","    }\n","\n","    print(f'after feature selection: {X_design.shape}')\n","\n","    # Perform grid search with inner cross-validation, part 2\n","    model_1 = RandomizedSearchCV(pipeline_1b, param_distributions=param_grid_1b, n_iter=50, cv=inner_cv, scoring='f1', n_jobs=-1) \n","    model_1.fit(X_design, y_design)\n","    results = pd.DataFrame(model_1.cv_results_)\n","    results_1 = results_1.append(results,ignore_index=True)\n","\n","    # Define scores AFTER hyperparameter tuning \n","    y_pred_design_1_after = model_1.predict(X_design)\n","    f1_design_1_aft = f1_score(y_design, y_pred_design_1_after)\n","    f1_design_1_after.append(f1_design_1_aft)\n","    \n","    y_pred_test_1_after = model_1.predict(X_test)\n","    y_pred_1_all.append(y_pred_test_1_after)\n","    \n","    f1_test_1_aft = f1_score(y_test_1, y_pred_test_1_after)\n","    f1_test_1_after.append(f1_test_1_aft)\n","\n","    # Access and store the best set of hyperparameters of each outer-CV loop in a DataFrame\n","    best_hp_1 = best_hp_1.append(model_1.best_params_,ignore_index=True)\n","    # Stores the optimum model in best_pipe\n","    best_pipe_1.append(model_1.best_estimator_)\n","\n","# Save results of inner CV into .csv file\n","results_1.to_csv('results_1.csv', index=False)\n","\n","print(f'Mean and std of F1 scores of pipeline 1: {statistics.mean(f1_test_1_after)} +/- {statistics.stdev(f1_test_1_after)}')\n","print(f'The optimal hyperparameters per split: {best_hp_1}')\n","print(f'The best pipes per split {best_pipe_1}')\n","print(f'The design F1 scores before tuning {f1_design_1_before}')\n","print(f'The test F1 scores before tuning {f1_test_1_before}')\n","print(f'The design F1 scores after tuning {f1_design_1_after}')\n","print(f'The test F1 scores afer tuning {f1_test_1_after}')\n","\n","data_1 = [f1_design_1_after, f1_test_1_after]\n","sns.boxplot(data=data_1)\n","plt.title('Boxplot F1 scores design and test pipeline 1')\n","plt.xlabel('design and test')\n","plt.ylabel('F1 score score')\n","plt.show()\n","\n","# Loop over rows and compute precision recall curve for each row\n","for i in range(len(y_pred_1_all)):\n","    precision, recall, thresholds = precision_recall_curve(y_test_1_all[i], y_pred_1_all[i])\n","    auc = average_precision_score(y_test_1_all[i], y_pred_1_all[i])\n","\n","    # Plot the ROC curve for each row\n","    plt.plot(recall, precision, lw=2, label='PR curve it. %d (AP = %0.2f)' % (i+1, auc))\n","\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-recall curve for all rows')\n","plt.legend(loc=\"lower right\", fontsize=8)\n","plt.show()"],"metadata":{"id":"rnjkGpz8xpCd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Pipeline 2: PCA + Univariate -> Quadratic Discriminant analysis"],"metadata":{"id":"fs2JpG9Zy3ib"}},{"cell_type":"code","source":["# PIPELINE 2\n","# Define outer and inner cross validation\n","outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","inner_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n","\n","# Creating empty arrays\n","f1_design_2_before = []\n","f1_test_2_before = []\n","f1_design_2_after = []\n","f1_test_2_after = []\n","results_2 = pd.DataFrame()\n","best_pipe_2 = []\n","best_hp_2_before = pd.DataFrame()\n","best_hp_2 = pd.DataFrame()\n","y_test_2_all = []\n","y_pred_2_all = []\n","\n","for design_index, test_index in outer_cv.split(X, y): \n","    X_design = X.transpose()[design_index]\n","    X_design = X_design.transpose()\n","    print(f'Size_X_design {X_design.shape}') # print size of X_design\n","    y_design = y[design_index]\n","    \n","    X_test = X.transpose()[test_index]\n","    X_test = X_test.transpose()\n","    y_test_2 = y[test_index].tolist()\n","    y_test_2_all.append(y_test_2)\n","    print(f'Size X_test {X_test.shape}')     # print size of X_test\n","    \n","    # remove outliers\n","    X_design = removing_outliers(X_design)\n","    X_test = removing_outliers(X_test)\n","\n","    # Correct missing data\n","    X_design = missing_data(X_design)\n","    X_test = missing_data(X_test)\n","\n","    # balance the classes, so design set consists of 50% normal and 50% abnormal ECG's\n","    ros = RandomOverSampler(sampling_strategy='minority')\n","    X_resampled, y_resampled = ros.fit_resample(X_design, y_design)\n","    X_design = X_resampled\n","    y_design = y_resampled   \n","\n","    print(f'shape after balancing {X_design.shape}')\n","    \n","    # Define pipeline 2\n","    pipeline_2a = Pipeline([\n","        ('scaler', RobustScaler()),\n","        ('var_threshold', VarianceThreshold(threshold=0.0)),\n","        ('pca', PCA(n_components=0.5)),\n","    ])\n","\n","    param_grid_2a = {\n","        'pca__n_components': [0.5],#0.75, 0.9, 0.95, 0.99],\n","        }\n","\n","    # Perform grid search with inner cross-validation, part 1\n","    rand_search_2a = RandomizedSearchCV(pipeline_2a, param_distributions=param_grid_2a, n_iter=10, cv=inner_cv, scoring='f1', n_jobs=-1) #klopt n__iter\n","    rand_search_2a.fit(X_design, y_design) # klopt dit fit_transform?\n","    X_design = rand_search_2a.best_estimator_.transform(X_design)\n","    X_test = rand_search_2a.best_estimator_.transform(X_test)\n","    \n","    # Access and store the best set of hyperparameters of each outer-CV loop in a DataFrame\n","    best_hp_2_before = best_hp_2_before.append(rand_search_2a.best_params_,ignore_index=True)\n","    print(best_hp_2_before)\n","    print(f'shape of X_design after pca {X_design.shape}')\n","\n","    sel_kb = SelectKBest(f_classif, k='all')\n","    sel_kb.fit(X_design, y_design)\n","    p_values = sel_kb.pvalues_\n","\n","    reject_fdr, pvals_fdr, _, _ = multipletests(pvals=p_values, alpha=0.05, method='fdr_bh')\n","    features_selected=np.array(np.where(reject_fdr)[0])\n","    print(f'size of features selected{features_selected.shape}')\n","    X_design = X_design[:,features_selected]\n","    X_test = X_test[:,features_selected]\n","\n","    # design the classifier on the selected features with the best hyperparameters to create best designed classifier\n","    model_2 = QuadraticDiscriminantAnalysis()\n","    model_2.fit(X_design, y_design)\n","\n","    # Define scores AFTER hyperparameter tuning \n","    y_pred_design_2_after = model_2.predict(X_design)\n","    f1_design_2_aft = f1_score(y_design, y_pred_design_2_after)\n","    f1_design_2_after.append(f1_design_2_aft)\n","   \n","    y_pred_test_2_after = model_2.predict(X_test)\n","    y_pred_2_all.append(y_pred_test_2_after)\n","   \n","    f1_test_2_aft = f1_score(y_test_2, y_pred_test_2_after)\n","    f1_test_2_after.append(f1_test_2_aft)\n","\n","print(f'Mean and std of F1 scores of pipeline 1: {statistics.mean(f1_test_2_after)} +/- {statistics.stdev(f1_test_2_after)}')\n","print(f'The optimal hyperparameters per split: {best_hp_2}')\n","print(f'The best pipes per split {best_pipe_2}')\n","print(f'The design F1 scores before tuning {f1_design_2_before}')\n","print(f'The test F1 scores before tuning {f1_test_2_before}')\n","print(f'The design F1 scores after tuning {f1_design_2_after}')\n","print(f'The test F1 scores afer tuning {f1_test_2_after}')\n","\n","data_2 = [f1_design_2_after, f1_test_2_after]\n","sns.boxplot(data=data_2)\n","plt.title('Boxplot F1 scores design and test pipeline 2')\n","plt.xlabel('design and test')\n","plt.ylabel('F1 score score')\n","plt.show()\n","\n","# Loop over rows and compute precision recall curve for each row\n","for i in range(len(y_pred_2_all)):\n","    precision, recall, thresholds = precision_recall_curve(y_test_2_all[i], y_pred_2_all[i])\n","    auc = average_precision_score(y_test_2_all[i], y_pred_2_all[i])\n","\n","    # Plot the ROC curve for each row\n","    plt.plot(recall, precision, lw=2, label='PR curve it. %d (AP = %0.2f)' % (i+1, auc))\n","\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-recall curve for all rows pipeline 2')\n","plt.legend(loc=\"lower right\", fontsize=8)\n","plt.show()"],"metadata":{"id":"p_OXtR6qy-aB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Pipeline 3"],"metadata":{"id":"kf25y4FtzYdl"}},{"cell_type":"code","source":["# PIPELINE 3\n","# Define outer and inner cross validation\n","outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42) \n","inner_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n","\n","# Creating empty arrays\n","f1_design_3_before = []\n","f1_test_3_before = []\n","f1_design_3_after = []\n","f1_test_3_after = []\n","results_3 = pd.DataFrame()\n","best_pipe_3 = []\n","best_hp_3_before = pd.DataFrame()\n","best_hp_3 = pd.DataFrame()\n","y_test_3_all = []\n","y_pred_3_all = []\n","\n","for design_index, test_index in outer_cv.split(X, y): \n","    X_design = X.transpose()[design_index]\n","    X_design = X_design.transpose()\n","    print(f'Size_X_design {X_design.shape}') # print size of X_design\n","    y_design = y[design_index]\n","    \n","    X_test = X.transpose()[test_index]\n","    X_test = X_test.transpose()\n","    y_test_3 = y[test_index].tolist()\n","    y_test_3_all.append(y_test_3)\n","    print(f'Size X_test {X_test.shape}')     # print size of X_test\n","    \n","    X_design = removing_outliers(X_design)\n","    X_test = removing_outliers(X_test)\n","    X_design = missing_data(X_design)\n","    X_test = missing_data(X_test)\n","\n","    # balance the classes, so design set consists of 50% normal and 50% abnormal ECG's\n","    ros = RandomOverSampler(sampling_strategy='minority')\n","    X_resampled, y_resampled = ros.fit_resample(X_design, y_design)\n","    X_design = X_resampled\n","    y_design = y_resampled   \n","    print(f'shape after balancing {X_design.shape}')\n","    \n","    # Define pipeline 3\n","    pipeline_3a = Pipeline([\n","        ('scaler', RobustScaler()),\n","        ('var_threshold', VarianceThreshold(threshold=0.0)),\n","        ('pca', PCA(n_components=0.5)),\n","    ])\n","\n","    param_grid_3a = {\n","        'pca__n_components': [0.5],#0.75, 0.9, 0.95, 0.99],\n","        }\n","\n","    # Perform grid search with inner cross-validation, part 1\n","    rand_search_3a = RandomizedSearchCV(pipeline_3a, param_distributions=param_grid_3a, n_iter=10, cv=inner_cv, scoring='f1', n_jobs=-1) #klopt n__iter\n","    rand_search_3a.fit(X_design, y_design) # klopt dit fit_transform?\n","    X_design = rand_search_3a.best_estimator_.transform(X_design)\n","    X_test = rand_search_3a.best_estimator_.transform(X_test)\n","    \n","    # Access and store the best set of hyperparameters of each outer-CV loop in a DataFrame\n","    best_hp_3_before = best_hp_3_before.append(rand_search_3a.best_params_,ignore_index=True)\n","    print(f'shape of X_design after pca {X_design.shape}')\n","\n","    # univariate feature selection\n","    sel_kb = SelectKBest(f_classif, k='all')\n","    sel_kb.fit(X_design, y_design)\n","    p_values = sel_kb.pvalues_\n","\n","    reject_fdr, pvals_fdr, _, _ = multipletests(pvals=p_values, alpha=0.05, method='fdr_bh')\n","    features_selected=np.array(np.where(reject_fdr)[0])\n","    print(f'size of features selected{features_selected.shape}')\n","    X_design = X_design[:,features_selected]\n","    X_test = X_test[:,features_selected]\n","        \n","    print(f'shape of X_design after univariate: {X_design.shape}')\n","    \n","    # pipeline 3b\n","    pipeline_3b = Pipeline([    \n","        ('clf', SVC(kernel='linear'))\n","    ])\n","\n","    # Define scores BEFORE hyperparameter tuning\n","    pipeline_3b.fit(X_design, y_design)\n"," \n","    y_pred_design_3 = pipeline_3b.predict(X_design)\n","    f1_design_3_bef = f1_score(y_design, y_pred_design_3)\n","    f1_design_3_before.append(f1_design_3_bef)\n","\n","    y_pred_test_3_before = pipeline_3b.predict(X_test)\n","    f1_test_3_bef = f1_score(y_test_3, y_pred_test_3_before)\n","    f1_test_3_before.append(f1_test_3_bef)\n","\n","    # Define hyperparameters of pipeline 3\n","    param_grid_3b = {\n","    'clf__C': np.logspace(-3, 1, 20),\n","    }\n","\n","    # Perform grid search with inner cross-validation, part 1\n","    model_3 = RandomizedSearchCV(pipeline_3b, param_distributions=param_grid_3b, cv=inner_cv, scoring='f1', n_iter=50, n_jobs=-1) # optimize parameters\n","    model_3.fit(X_design, y_design)\n","\n","    results = pd.DataFrame(model_3.cv_results_)\n","    results_3 = results_3.append(results,ignore_index=True)\n","\n","    # Define scores AFTER hyperparameter tuning \n","    y_pred_design_3_after = model_3.predict(X_design)\n","    f1_design_3_aft = f1_score(y_design, y_pred_design_3_after)\n","    f1_design_3_after.append(f1_design_3_aft)\n","   \n","    y_pred_test_3_after = model_3.predict(X_test)\n","    y_pred_3_all.append(y_pred_test_3_after)\n","   \n","    f1_test_3_aft = f1_score(y_test_3, y_pred_test_3_after)\n","    f1_test_3_after.append(f1_test_3_aft)\n","\n","\n","    # Access and store the best set of hyperparameters of each outer-CV loop in a DataFrame\n","    best_hp_3 = best_hp_3.append(model_3.best_params_,ignore_index=True)\n","    # Stores the optimum model in best_pipe\n","    best_pipe_3.append(model_3.best_estimator_)\n","\n","# Save results of inner CV into .csv file\n","results_3.to_csv('results_3.csv', index=False)\n","\n","print(f'Mean and std of F1 scores of pipeline 3: {statistics.mean(f1_test_3_after)} +/- {statistics.stdev(f1_test_3_after)}')\n","print(f'The optimal hyperparameters per split: {best_hp_3}')\n","print(f'The best pipes per split {best_pipe_3}')\n","print(f'The design F1 scores before tuning {f1_design_3_before}')\n","print(f'The test F1 scores before tuning {f1_test_3_before}')\n","print(f'The design F1 scores after tuning {f1_design_3_after}')\n","print(f'The test F1 scores afer tuning {f1_test_3_after}')\n","\n","data_3 = [f1_design_3_after, f1_test_3_after]\n","sns.boxplot(data=data_3)\n","plt.title('Boxplot F1 scores design and test pipeline 3')\n","plt.xlabel('design and test')\n","plt.ylabel('F1 score score')\n","plt.show()\n","\n","# Loop over rows and compute precision recall curve for each row\n","for i in range(len(y_pred_3_all)):\n","    precision, recall, thresholds = precision_recall_curve(y_test_3_all[i], y_pred_3_all[i])\n","    auc = average_precision_score(y_test_3_all[i], y_pred_3_all[i])\n","\n","    # Plot the ROC curve for each row\n","    plt.plot(recall, precision, lw=2, label='PR curve it. %d (AP = %0.2f)' % (i+1, auc))\n","\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-recall curve for all rows')\n","plt.legend(loc=\"lower right\", fontsize=8)\n","plt.show()"],"metadata":{"id":"ihFqgjuSzsJn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Pipeline 4:PCA + Univariate -> KNN"],"metadata":{"id":"-bWqOArv0Etj"}},{"cell_type":"code","source":["# PIPELINE 4\n","# Define outer and inner cross validation\n","outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42) \n","inner_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n","\n","# Creating empty arrays\n","f1_design_4_before = []\n","f1_test_4_before = []\n","f1_design_4_after = []\n","f1_test_4_after = []\n","results_4 = pd.DataFrame()\n","best_pipe_4 = []\n","best_hp_4_before = pd.DataFrame()\n","best_hp_4 = pd.DataFrame()\n","y_test_4_all = []\n","y_pred_4_all = []\n","\n","for design_index, test_index in outer_cv.split(X, y): \n","    X_design = X.transpose()[design_index]\n","    X_design = X_design.transpose()\n","    print(f'Size_X_design {X_design.shape}') # print size of X_design\n","    y_design = y[design_index]\n","    \n","    X_test = X.transpose()[test_index]\n","    X_test = X_test.transpose()\n","    y_test_4 = y[test_index].tolist()\n","    y_test_4_all.append(y_test_4)\n","    print(f'Size X_test {X_test.shape}')     # print size of X_test\n","\n","    # remove outliers\n","    X_design = removing_outliers(X_design)\n","    X_test = removing_outliers(X_test)\n","\n","    # Correct missing data\n","    X_design = missing_data(X_design)\n","    X_test = missing_data(X_test)\n","\n","    # balance the classes, so design set consists of 50% normal and 50% abnormal ECG's\n","    ros = RandomOverSampler(sampling_strategy='minority')\n","    X_resampled, y_resampled = ros.fit_resample(X_design, y_design)\n","    X_design = X_resampled\n","    y_design = y_resampled   \n","    print(f'shape after balancing {X_design.shape}')\n","\n","    # Define pipeline 4a\n","    pipeline_4a = Pipeline([\n","        ('scaler', RobustScaler()),\n","        ('var_threshold', VarianceThreshold(threshold=0.0)),\n","        ('pca', PCA(n_components=0.5)),\n","    ])\n","\n","    param_grid_4a = {\n","        'pca__n_components': [0.5],#0.75, 0.9, 0.95, 0.99],\n","        }\n","\n","    # Perform grid search with inner cross-validation, part 1\n","    rand_search_4a = RandomizedSearchCV(pipeline_4a, param_distributions=param_grid_4a, n_iter=10, cv=inner_cv, scoring='f1', n_jobs=-1) #klopt n__iter\n","    rand_search_4a.fit(X_design, y_design) # klopt dit fit_transform?\n","    X_design = rand_search_4a.best_estimator_.transform(X_design)\n","    X_test = rand_search_4a.best_estimator_.transform(X_test)\n","    \n","    # Access and store the best set of hyperparameters of each outer-CV loop in a DataFrame\n","    best_hp_4_before = best_hp_4_before.append(rand_search_4a.best_params_,ignore_index=True)\n","    print(f'shape of X_design after pca {X_design.shape}')\n","\n","    # univariate feature selection\n","    sel_kb = SelectKBest(f_classif, k='all')\n","    sel_kb.fit(X_design, y_design)\n","    p_values = sel_kb.pvalues_\n","\n","    reject_fdr, pvals_fdr, _, _ = multipletests(pvals=p_values, alpha=0.05, method='fdr_bh')\n","    features_selected=np.array(np.where(reject_fdr)[0])\n","    print(f'size of features selected{features_selected.shape}')\n","    X_design = X_design[:,features_selected]\n","    X_test = X_test[:,features_selected]\n","        \n","    print(f'shape of X_design after univariate: {X_design.shape}')\n","    \n","    # pipeline 4b\n","    pipeline_4b = Pipeline([    \n","        ('clf', KNeighborsClassifier())\n","    ])\n","\n","    # Define scores BEFORE hyperparameter tuning\n","    pipeline_4b.fit(X_design, y_design)\n"," \n","    y_pred_design_4 = pipeline_4b.predict(X_design)\n","    f1_design_4_bef = f1_score(y_design, y_pred_design_4)\n","    f1_design_4_before.append(f1_design_4_bef)\n","\n","    y_pred_test_4_before = pipeline_4b.predict(X_test)\n","    f1_test_4_bef = f1_score(y_test_4, y_pred_test_4_before)\n","    f1_test_4_before.append(f1_test_4_bef)\n","    \n","    # Define hyperparameters of pipeline 4\n","    param_grid_4b = {\n","    'clf__n_neighbors': list(range(4,26,2)), \n","    'clf__p': [1,2],\n","    'clf__leaf_size': np.arange(1,26,1)\n","    }\n","\n","    # Perform grid search with inner cross-validation, part 1\n","    model_4 = RandomizedSearchCV(pipeline_4b, param_distributions=param_grid_4b, cv=inner_cv, scoring='f1', n_iter= 50, n_jobs=-1) # optimize parameters\n","    model_4.fit(X_design, y_design)\n","\n","    results = pd.DataFrame(model_4.cv_results_)\n","    results_4 = results_4.append(results,ignore_index=True)\n","\n","    # Define scores AFTER hyperparameter tuning \n","    y_pred_design_4_after = model_4.predict(X_design)\n","    f1_design_4_aft = f1_score(y_design, y_pred_design_4_after)\n","    f1_design_4_after.append(f1_design_4_aft)\n","   \n","    y_pred_test_4_after = model_4.predict(X_test)\n","    y_pred_4_all.append(y_pred_test_4_after)\n","   \n","    f1_test_4_aft = f1_score(y_test_4, y_pred_test_4_after)\n","    f1_test_4_after.append(f1_test_4_aft)\n","\n","    # Access and store the best set of hyperparameters of each outer-CV loop in a DataFrame\n","    best_hp_4 = best_hp_4.append(model_4.best_params_,ignore_index=True)\n","    # Stores the optimum model in best_pipe\n","    best_pipe_4.append(model_4.best_estimator_)\n","\n","# Save results of inner CV into .csv file\n","results_4.to_csv('results_4.csv', index=False)\n","\n","print(f'Mean and std of F1 scores of pipeline 4: {statistics.mean(f1_test_4_after)} +/- {statistics.stdev(f1_test_4_after)}')\n","print(f'The optimal hyperparameters per split: {best_hp_4}')\n","print(f'The best pipes per split {best_pipe_4}')\n","print(f'The design F1 scores before tuning {f1_design_4_before}')\n","print(f'The test F1 scores before tuning {f1_test_4_before}')\n","print(f'The design F1 scores after tuning {f1_design_4_after}')\n","print(f'The test F1 scores afer tuning {f1_test_4_after}')\n","\n","data_4 = [f1_design_4_after, f1_test_4_after]\n","sns.boxplot(data=data_4)\n","plt.title('Boxplot F1 scores design and test pipeline 4')\n","plt.xlabel('design and test')\n","plt.ylabel('F1 score score')\n","plt.show()\n","\n","# Confusion matrix\n","# convert numpy arrays to Python lists\n","y_pred_4_all = [arr.tolist() for arr in y_pred_4_all]\n","y_test_4_all = np.array(y_test_4_all)\n","y_pred_4_all = np.array(y_pred_4_all)\n","y_test_4_all_confusion = [item for sublist in y_test_4_all for item in sublist]\n","y_pred_4_all_confusion = [item for sublist in y_pred_4_all for item in sublist]\n","\n","# Loop over rows and compute precision recall curve for each row\n","for i in range(len(y_pred_4_all)):\n","    precision, recall, thresholds = precision_recall_curve(y_test_4_all[i], y_pred_4_all[i])\n","    auc = average_precision_score(y_test_4_all[i], y_pred_4_all[i])\n","\n","    # Plot the ROC curve for each row\n","    plt.plot(recall, precision, lw=2, label='PR curve it. %d (AP = %0.2f)' % (i+1, auc))\n","\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-recall curve for all rows')\n","plt.legend(loc=\"lower right\", fontsize=8)\n","plt.show()"],"metadata":{"id":"Kk5rPzuu0MsN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Pipeline 5: LASSO -> KNN"],"metadata":{"id":"GqGugMuY06P8"}},{"cell_type":"code","source":["# PIPELINE 5\n","\n","# Define outer and inner cross validation\n","outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42) \n","inner_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n","\n","# Creating ampty arrays\n","f1_design_5_before = []\n","f1_test_5_before = []\n","f1_design_5_after = []\n","f1_test_5_after = []\n","results_5 = pd.DataFrame()\n","best_pipe_5 = []\n","best_hp_5_before = pd.DataFrame()\n","best_hp_5 = pd.DataFrame()\n","y_test_5_all = []\n","y_pred_5_all = []\n","\n","for design_index, test_index in outer_cv.split(X, y): \n","    X_design = X.transpose()[design_index]\n","    X_design = X_design.transpose()\n","    print(f'Size_X_design {X_design.shape}') # print size of X_design\n","    y_design = y[design_index]\n","    \n","    X_test = X.transpose()[test_index]\n","    X_test = X_test.transpose()\n","    y_test_5 = y[test_index].tolist()\n","    y_test_5_all.append(y_test_5)\n","    print(f'Size X_test {X_test.shape}')     # print size of X_test\n","\n","    # remove outliers\n","    X_design = removing_outliers(X_design)\n","    X_test = removing_outliers(X_test)\n","\n","    # Correct missing data\n","    X_design = missing_data(X_design)\n","    X_test = missing_data(X_test)\n","\n","    # balance the classes, so design set consists of 50% normal and 50% abnormal ECG's\n","    ros = RandomOverSampler(sampling_strategy='minority')\n","    X_resampled, y_resampled = ros.fit_resample(X_design, y_design)\n","    X_design = X_resampled\n","    y_design = y_resampled   \n","\n","    print(f'shape after balancing {X_design.shape}')  \n","\n","    # Scaling the data\n","    scaler = RobustScaler()\n","    X_design = scaler.fit_transform(X_design)\n","    X_test = scaler.transform(X_test)\n","\n","    ## PIPELINE 5: RobustScaler --> LASSO --> KNN\n","    # Define pipeline 5\n","    pipeline_5a = Pipeline([\n","        ('lasso', Lasso()),\n","    ])\n","    # Define hyperparameters of pipeline 5\n","    param_grid_5a = {\n","    'lasso__alpha': np.logspace(-10, 1, 100),\n","    }\n","\n","    # Perform randomized search with inner cross-validation to find best alpha\n","    rand_search_5a = RandomizedSearchCV(pipeline_5a, param_distributions=param_grid_5a, n_iter=50, cv=inner_cv, scoring='f1',n_jobs=-1) # optimize parameters\n","    rand_search_5a.fit(X_design, y_design)\n","    \n","    # Create a new Lasso model using the best alpha value\n","    lasso = Lasso(alpha=rand_search_5a.best_params_['lasso__alpha'])\n","    lasso.fit(X_design, y_design)\n","\n","    # Get the coefficients of the Lasso model, find them and define the new X_design with less features\n","    coef = lasso.coef_\n","    selected_features = np.where(coef != 0)[0]\n","    X_design = X_design[:, selected_features]\n","    X_test = X_test[:, selected_features]\n","    print(f'This is the size of X_design after LASSO: {X_design.shape}')\n","\n","    # Access and store the best set of hyperparameters of each outer-CV loop in a DataFrame\n","    best_hp_5_before = best_hp_5_before.append(rand_search_5a.best_params_,ignore_index=True)\n","    print(f'This is the size of X_design after LASSO: {X_design.shape}')\n","\n","    # Define pipeline 5b\n","    pipeline_5b = Pipeline([\n","        ('clf', KNeighborsClassifier())\n","        ])\n","    \n","    # Define scores BEFORE hyperparameter tuning\n","    pipeline_5b.fit(X_design, y_design)\n"," \n","    y_pred_design_5 = pipeline_5b.predict(X_design)\n","    f1_design_5_bef = f1_score(y_design, y_pred_design_5)\n","    f1_design_5_before.append(f1_design_5_bef)\n","\n","    y_pred_test_5_before = pipeline_5b.predict(X_test)\n","    f1_test_5_bef = f1_score(y_test_5, y_pred_test_5_before)\n","    f1_test_5_before.append(f1_test_5_bef)\n","\n","    # Define hyperparameters of pipeline 5b\n","    param_grid_5b = {'clf__n_neighbors': list(range(4,26,2)),\n","                  'clf__p': [1,2],\n","                  'clf__leaf_size': np.arange(1,26,1)\n","                }\n","\n","    # Perform grid search with inner cross-validation, part 1\n","    model_5 = RandomizedSearchCV(pipeline_5b, param_distributions=param_grid_5b, n_iter=50, cv=inner_cv, scoring='f1', n_jobs=-1) # optimize parameters\n","    model_5.fit(X_design, y_design)\n","\n","    # Storing results cross-validation\n","    results = pd.DataFrame(model_5.cv_results_)\n","    results_5 = results_5.append(results,ignore_index=True)\n","\n","    # Define scores AFTER hyperparameter tuning \n","    y_pred_design_5_after = model_5.predict(X_design)\n","    f1_design_5_aft = f1_score(y_design, y_pred_design_5_after)\n","    f1_design_5_after.append(f1_design_5_aft)\n","   \n","    y_pred_test_5_after = model_5.predict(X_test)\n","    y_pred_5_all.append(y_pred_test_5_after)\n","   \n","    f1_test_5_aft = f1_score(y_test_5, y_pred_test_5_after)\n","    f1_test_5_after.append(f1_test_5_aft)\n","\n","    # Access and store the best set of hyperparameters of each outer-CV loop in a DataFrame\n","    best_hp_5 = best_hp_5.append(model_5.best_params_,ignore_index=True)\n","    # Stores the optimum model in best_pipe\n","    best_pipe_5.append(model_5.best_estimator_)\n","\n","# Save results of inner CV into .csv file\n","results_5.to_csv('results_5.csv', index=False)\n","\n","print(f'Mean and std of F1 scores of pipeline 5: {statistics.mean(f1_test_5_after)} +/- {statistics.stdev(f1_test_5_after)}')\n","print(f'The optimal hyperparameters per split: {best_hp_5}')\n","print(f'The best pipes per split {best_pipe_5}')\n","print(f'The design F1 scores before tuning {f1_design_5_before}')\n","print(f'The test F1 scores before tuning {f1_test_5_before}')\n","print(f'The design F1 scores after tuning {f1_design_5_after}')\n","print(f'The test F1 scores afer tuning {f1_test_5_after}')\n","\n","data_5 = [f1_design_5_after, f1_test_5_after]\n","sns.boxplot(data=data_5)\n","plt.title('Boxplot F1 scores design and test pipeline 5')\n","plt.xlabel('design and test')\n","plt.ylabel('F1 score score')\n","plt.show()\n","\n","# Loop over rows and compute precision recall curve for each row\n","for i in range(len(y_pred_5_all)):\n","    precision, recall, thresholds = precision_recall_curve(y_test_5_all[i], y_pred_5_all[i])\n","    auc = average_precision_score(y_test_5_all[i], y_pred_5_all[i])\n","\n","    # Plot the ROC curve for each row\n","    plt.plot(recall, precision, lw=2, label='PR curve it. %d (AP = %0.2f)' % (i+1, auc))\n","\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-recall curve for all rows')\n","plt.legend(loc=\"lower right\", fontsize=8)\n","plt.show()"],"metadata":{"id":"57-faWGZ0-Hi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Pipeline 6: PCA + Univariate -> Random forest"],"metadata":{"id":"hZ3xrwmn1mdX"}},{"cell_type":"code","source":["# PIPELINE 6\n","# Define outer and inner cross validation\n","outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42) \n","inner_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n","\n","# Creating empty error\n","f1_design_6_before = []\n","f1_test_6_before = []\n","f1_design_6_after = []\n","f1_test_6_after = []\n","results_6 = pd.DataFrame()\n","best_pipe_6 = []\n","best_hp_6_before = pd.DataFrame()\n","best_hp_6 = pd.DataFrame()\n","y_test_6_all = []\n","y_pred_6_all = []\n","\n","for design_index, test_index in outer_cv.split(X, y): \n","    X_design = X.transpose()[design_index]\n","    X_design = X_design.transpose()\n","    print(f'Size_X_design {X_design.shape}') # print size of X_design\n","    y_design = y[design_index]\n","    \n","    X_test = X.transpose()[test_index]\n","    X_test = X_test.transpose()\n","    y_test_6 = y[test_index].tolist()\n","    y_test_6_all.append(y_test_6)\n","    print(f'Size X_test {X_test.shape}')     # print size of X_test\n","    \n","    # remove outliers\n","    X_design = removing_outliers(X_design)\n","    X_test = removing_outliers(X_test)\n","\n","    # Correct missing data\n","    X_design = missing_data(X_design)\n","    X_test = missing_data(X_test)\n","\n","    # balance the classes, so design set consists of 50% normal and 50% abnormal ECG's\n","    ros = RandomOverSampler(sampling_strategy='minority')\n","    X_resampled, y_resampled = ros.fit_resample(X_design, y_design)\n","    X_design = X_resampled\n","    y_design = y_resampled   \n","\n","    print(f'shape after balancing {X_design.shape}')\n","    \n","    # Define pipeline 6a\n","    pipeline_6a = Pipeline([\n","        ('scaler', RobustScaler()),\n","        ('var_threshold', VarianceThreshold(threshold=0.0)),\n","        ('pca', PCA(n_components=0.5)),\n","    ])\n","\n","    param_grid_6a = {\n","        'pca__n_components': [0.5],#,0.75, 0.9, 0.95, 0.99],\n","        }\n","\n","    # Perform grid search with inner cross-validation, part 1\n","    rand_search_6a = RandomizedSearchCV(pipeline_6a, param_distributions=param_grid_6a, n_iter=10, cv=inner_cv, scoring='f1', n_jobs=-1) #klopt n__iter\n","    rand_search_6a.fit(X_design, y_design)\n","    X_design = rand_search_6a.best_estimator_.transform(X_design)\n","    X_test = rand_search_6a.best_estimator_.transform(X_test)\n","    \n","    # Access and store the best set of hyperparameters of each outer-CV loop in a DataFrame\n","    best_hp_6_before = best_hp_6_before.append(rand_search_6a.best_params_,ignore_index=True)\n","    print(f'shape of X_design after pca {X_design.shape}')\n","\n","    # univariate feature selection\n","    sel_kb = SelectKBest(f_classif, k='all')\n","    sel_kb.fit(X_design, y_design)\n","    p_values = sel_kb.pvalues_\n","\n","    reject_fdr, pvals_fdr, _, _ = multipletests(pvals=p_values, alpha=0.05, method='fdr_bh')\n","    features_selected=np.array(np.where(reject_fdr)[0])\n","    print(f'size of features selected{features_selected.shape}')\n","    X_design = X_design[:,features_selected]\n","    X_test = X_test[:,features_selected]\n","        \n","    print(f'shape of X_design after univariate: {X_design.shape}')\n","    \n","    # pipeline 6b\n","    pipeline_6b = Pipeline([    \n","        ('clf', RandomForestClassifier())\n","    ])\n","\n","    # Define scores BEFORE hyperparameter tuning\n","    pipeline_6b.fit(X_design, y_design)\n"," \n","    y_pred_design_6 = pipeline_6b.predict(X_design)\n","    f1_design_6_bef = f1_score(y_design, y_pred_design_6)\n","    f1_design_6_before.append(f1_design_6_bef)\n","\n","    y_pred_test_6_before = pipeline_6b.predict(X_test)\n","    f1_test_6_bef = f1_score(y_test_6, y_pred_test_6_before)\n","    f1_test_6_before.append(f1_test_6_bef)\n","    \n","    # Define hyperparameters of pipeline 6\n","    param_grid_6b = {'clf__n_estimators' : range(2,6),\n","                    'clf__criterion' :['gini','entropy','log_loss'],\n","                    'clf__min_samples_split':range(2,10),\n","                    'clf__min_samples_leaf':range(1,10),\n","                    'clf__min_weight_fraction_leaf' : np.linspace(0, 0.5, 25),\n","                    'clf__max_features':['sqrt','log2',None],\n","                    'clf__bootstrap':[True,False],\n","                    'clf__warm_start':[True,False]\n","                    }\n","\n","    # Perform grid search with inner cross-validation, part 1\n","    model_6 = RandomizedSearchCV(pipeline_6b, param_distributions=param_grid_6b, cv=inner_cv, scoring='f1', n_iter=50, n_jobs=-1) # optimize parameters\n","    model_6.fit(X_design, y_design)\n","\n","    results = pd.DataFrame(model_6.cv_results_)\n","    results_6 = results_6.append(results,ignore_index=True)\n","\n","    # Define scores AFTER hyperparameter tuning \n","    y_pred_design_6_after = model_6.predict(X_design)\n","    f1_design_6_aft = f1_score(y_design, y_pred_design_6_after)\n","    f1_design_6_after.append(f1_design_6_aft)\n","   \n","    y_pred_test_6_after = model_6.predict(X_test)\n","    y_pred_6_all.append(y_pred_test_6_after)\n","   \n","    f1_test_6_aft = f1_score(y_test_6, y_pred_test_6_after)\n","    f1_test_6_after.append(f1_test_6_aft)\n","\n","    # Access and store the best set of hyperparameters of each outer-CV loop in a DataFrame\n","    best_hp_6 = best_hp_6.append(model_6.best_params_,ignore_index=True)\n","    # Stores the optimum model in best_pipe\n","    best_pipe_6.append(model_6.best_estimator_)\n","\n","# Save results of inner CV into .csv file\n","results_6.to_csv('results_6.csv', index=False)\n","\n","print(f'Mean and std of F1 scores of pipeline 1: {statistics.mean(f1_test_6_after)} +/- {statistics.stdev(f1_test_6_after)}')\n","print(f'The optimal hyperparameters per split: {best_hp_6}')\n","print(f'The best pipes per split {best_pipe_6}')\n","print(f'The design F1 scores before tuning {f1_design_6_before}')\n","print(f'The test F1 scores before tuning {f1_test_6_before}')\n","print(f'The design F1 scores after tuning {f1_design_6_after}')\n","print(f'The test F1 scores afer tuning {f1_test_6_after}')\n","\n","data_6 = [f1_design_6_after, f1_test_6_after]\n","sns.boxplot(data=data_6)\n","plt.title('Boxplot F1 scores design and test pipeline 6')\n","plt.xlabel('design and test')\n","plt.ylabel('F1 score score')\n","plt.show()\n","\n","# Loop over rows and compute precision recall curve for each row\n","for i in range(len(y_pred_6_all)):\n","    precision, recall, thresholds = precision_recall_curve(y_test_6_all[i], y_pred_6_all[i])\n","    auc = average_precision_score(y_test_6_all[i], y_pred_6_all[i])\n","\n","    # Plot the ROC curve for each row\n","    plt.plot(recall, precision, lw=2, label='PR curve it. %d (AP = %0.2f)' % (i+1, auc))\n","\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-recall curve for all rows')\n","plt.legend(loc=\"lower right\", fontsize=8)\n","plt.show()"],"metadata":{"id":"gz6fTXu91qy9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Pipeline 7: LASSO -> Random forest"],"metadata":{"id":"t5O52Uz12l3A"}},{"cell_type":"code","source":["# # Define outer and inner cross validation\n","# outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42) \n","# inner_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n","\n","# # Creating empty arrays\n","# f1_design_7_before = []\n","# f1_test_7_before = []\n","# f1_design_7_after = []\n","# f1_test_7_after = []\n","# results_7 = pd.DataFrame()\n","# best_pipe_7 = []\n","# best_hp_7_before = pd.DataFrame()\n","# best_hp_7 = pd.DataFrame()\n","# y_test_7_all = []\n","# y_pred_7_all = []\n","\n","# for design_index, test_index in outer_cv.split(X, y): \n","#     X_design = X.transpose()[design_index]\n","#     X_design = X_design.transpose()\n","#     print(f'Size_X_design {X_design.shape}') # print size of X_design\n","#     y_design = y[design_index]\n","    \n","#     X_test = X.transpose()[test_index]\n","#     X_test = X_test.transpose()\n","#     y_test_7 = y[test_index].tolist()\n","#     y_test_7_all.append(y_test_7)\n","#     print(f'Size X_test {X_test.shape}')     # print size of X_test\n","\n","#     # remove outliers\n","#     X_design = removing_outliers(X_design)\n","#     X_test = removing_outliers(X_test)\n","\n","#     # Correct missing data\n","#     X_design = missing_data(X_design)\n","#     X_test = missing_data(X_test)\n","\n","#     # balance the classes, so design set consists of 50% normal and 50% abnormal ECG's\n","#     ros = RandomOverSampler(sampling_strategy='minority')\n","#     X_resampled, y_resampled = ros.fit_resample(X_design, y_design)\n","#     X_design = X_resampled\n","#     y_design = y_resampled  \n","#     print(f'shape after balancing {X_design.shape}')  \n","\n","#     # Scaling the data\n","#     scaler = RobustScaler()\n","#     X_design = scaler.fit_transform(X_design)\n","#     X_test = scaler.transform(X_test)\n","\n","#     # Define pipeline 7\n","#     pipeline_7a = Pipeline([\n","#         ('lasso', Lasso()),\n","#     ])\n","#     # Define hyperparameters of pipeline 5\n","#     param_grid_7a = {\n","#     'lasso__alpha': np.logspace(-10, 1, 100),\n","#     }\n","\n","#     # Perform randomized search with inner cross-validation to find best alpha\n","#     rand_search_7a = RandomizedSearchCV(pipeline_7a, param_distributions=param_grid_7a, n_iter =50, cv=inner_cv, scoring='f1',n_jobs=-1) # optimize parameters\n","#     rand_search_7a.fit(X_design, y_design)\n","    \n","#     # Create a new Lasso model using the best alpha value\n","#     lasso = Lasso(alpha=rand_search_7a.best_params_['lasso__alpha'])\n","#     lasso.fit(X_design, y_design)\n","\n","#     # Get the coefficients of the Lasso model, find them and define the new X_design with less features\n","#     coef = lasso.coef_\n","#     selected_features = np.where(coef != 0)[0]\n","#     X_design = X_design[:, selected_features]\n","#     X_test = X_test[:, selected_features]\n","#     print(f'This is the size of X_design after LASSO: {X_design.shape}')\n","\n","#     # Access and store the best set of hyperparameters of each outer-CV loop in a DataFrame\n","#     best_hp_7_before = best_hp_7_before.append(rand_search_7a.best_params_,ignore_index=True)\n","#     print(f'This is the size of X_design after LASSO: {X_design.shape}')\n","\n","#     # Define pipeline 7b\n","#     pipeline_7b = Pipeline([\n","#         ('clf', RandomForestClassifier())])\n","    \n","#     # Define scores BEFORE hyperparameter tuning\n","#     pipeline_7b.fit(X_design, y_design)\n"," \n","#     y_pred_design_7 = pipeline_7b.predict(X_design)\n","#     f1_design_7_bef = f1_score(y_design, y_pred_design_7)\n","#     f1_design_7_before.append(f1_design_7_bef)\n","\n","#     y_pred_test_7_before = pipeline_7b.predict(X_test)\n","#     f1_test_7_bef = f1_score(y_test_7, y_pred_test_7_before)\n","#     f1_test_7_before.append(f1_test_7_bef)\n","\n","#     # Define hyperparameters of pipeline 7b\n","#     param_grid_7b = {'clf__n_estimators' : range(2,6),\n","#                                'clf__criterion' :['gini','entropy','log_loss'],\n","#                                'clf__min_samples_split':range(2,10),\n","#                                'clf__min_samples_leaf':range(1,10),\n","#                                'clf__min_weight_fraction_leaf' : np.linspace(0, 0.5, 25),\n","#                                'clf__max_features':['sqrt','log2',None],\n","#                                'clf__bootstrap':[True,False],\n","#                                'clf__warm_start':[True,False],\n","#                                }\n","\n","#     # Perform grid search with inner cross-validation, part 1\n","#     model_7 = RandomizedSearchCV(pipeline_7b, param_distributions=param_grid_7b, n_iter=50, cv=inner_cv, scoring='f1', n_jobs=-1) # optimize parameters\n","#     model_7.fit(X_design, y_design)\n","\n","#     # Storing results cross-validation\n","#     results = pd.DataFrame(model_7.cv_results_)\n","#     results_7 = results_7.append(results,ignore_index=True)\n","\n","#     # Define scores AFTER hyperparameter tuning \n","#     y_pred_design_7_after = model_7.predict(X_design)\n","#     f1_design_7_aft = f1_score(y_design, y_pred_design_7_after)\n","#     f1_design_7_after.append(f1_design_7_aft)\n","   \n","#     y_pred_test_7_after = model_7.predict(X_test)\n","#     y_pred_7_all.append(y_pred_test_7_after)\n","   \n","#     f1_test_7_aft = f1_score(y_test_7, y_pred_test_7_after)\n","#     f1_test_7_after.append(f1_test_7_aft)\n","\n","#     # Access and store the best set of hyperparameters of each outer-CV loop in a DataFrame\n","#     best_hp_7 = best_hp_7.append(model_7.best_params_,ignore_index=True)\n","#     # Stores the optimum model in best_pipe\n","#     best_pipe_7.append(model_7.best_estimator_)\n","\n","# # Save results of inner CV into .csv file\n","# results_7.to_csv('results_7.csv', index=False)\n","\n","# print(f'Mean and std of F1 scores of pipeline 7: {statistics.mean(f1_test_7_after)} +/- {statistics.stdev(f1_test_7_after)}')\n","# print(f'The optimal hyperparameters per split: {best_hp_7}')\n","# print(f'The best pipes per split {best_pipe_7}')\n","# print(f'The design F1 scores before tuning {f1_design_7_before}')\n","# print(f'The test F1 scores before tuning {f1_test_7_before}')\n","# print(f'The design F1 scores after tuning {f1_design_7_after}')\n","# print(f'The test F1 scores afer tuning {f1_test_7_after}')\n","\n","# data_7 = [f1_design_7_after, f1_test_7_after]\n","# sns.boxplot(data=data_7)\n","# plt.title('Boxplot F1 scores design and test pipeline 7')\n","# plt.xlabel('design and test')\n","# plt.ylabel('F1 score score')\n","# plt.show()\n","\n","# # Loop over rows and compute precision recall curve for each row\n","# for i in range(len(y_pred_7_all)):\n","#     precision, recall, thresholds = precision_recall_curve(y_test_7_all[i], y_pred_7_all[i])\n","#     auc = average_precision_score(y_test_7_all[i], y_pred_7_all[i])\n","\n","#     # Plot the ROC curve for each row\n","#     plt.plot(recall, precision, lw=2, label='PR curve it. %d (AP = %0.2f)' % (i+1, auc))\n","\n","# plt.xlim([0.0, 1.0])\n","# plt.ylim([0.0, 1.05])\n","# plt.xlabel('Recall')\n","# plt.ylabel('Precision')\n","# plt.title('Precision-recall curve for all rows')\n","# plt.legend(loc=\"lower right\", fontsize=8)\n","# plt.show()"],"metadata":{"id":"jEhZPRmg2n3y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Confusion matrices and classification report"],"metadata":{"id":"4lTgYkJgygiz"}},{"cell_type":"code","source":["# Confusion matrices\n","# Pipeline 1\n","y_pred_1_all_con = [arr.tolist() for arr in y_pred_1_all]\n","y_test_1_all_con = np.array(y_test_1_all)\n","y_pred_1_all_con = np.array(y_pred_1_all_con)\n","y_test_1_all_confusion = [item for sublist in y_test_1_all_con for item in sublist]\n","y_pred_1_all_confusion = [item for sublist in y_pred_1_all_con for item in sublist]\n","\n","cm_1 = confusion_matrix(y_test_1_all_confusion, y_pred_1_all_confusion)\n","\n","sns.heatmap(cm_1, annot=True, cmap='Blues')\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","plt.title('Confusion matrix Pipeline 1')\n","plt.show()\n","\n","# Pipeline 2\n","y_pred_2_all_con = [arr.tolist() for arr in y_pred_2_all]\n","y_test_2_all_con = np.array(y_test_2_all)\n","y_pred_2_all_con = np.array(y_pred_2_all_con)\n","y_test_2_all_confusion = [item for sublist in y_test_2_all_con for item in sublist]\n","y_pred_2_all_confusion = [item for sublist in y_pred_2_all_con for item in sublist]\n","\n","cm_2 = confusion_matrix(y_test_2_all_confusion, y_pred_2_all_confusion)\n","\n","sns.heatmap(cm_2, annot=True, cmap='Blues')\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","plt.title('Confusion matrix Pipeline 2')\n","plt.show()\n","\n","# Pipeline 3\n","y_pred_3_all_con = [arr.tolist() for arr in y_pred_3_all]\n","y_test_3_all_con = np.array(y_test_3_all)\n","y_pred_3_all_con = np.array(y_pred_3_all_con)\n","y_test_3_all_confusion = [item for sublist in y_test_3_all_con for item in sublist]\n","y_pred_3_all_confusion = [item for sublist in y_pred_3_all_con for item in sublist]\n","\n","cm_3 = confusion_matrix(y_test_3_all_confusion, y_pred_3_all_confusion)\n","\n","sns.heatmap(cm_3, annot=True, cmap='Blues')\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","plt.title('Confusion matrix Pipeline 3')\n","plt.show()\n","\n","# Pipeline 4\n","y_pred_4_all_con = [arr.tolist() for arr in y_pred_4_all]\n","y_test_4_all_con = np.array(y_test_4_all)\n","y_pred_4_all_con = np.array(y_pred_4_all_con)\n","y_test_4_all_confusion = [item for sublist in y_test_4_all_con for item in sublist]\n","y_pred_4_all_confusion = [item for sublist in y_pred_4_all_con for item in sublist]\n","\n","cm_4 = confusion_matrix(y_test_4_all_confusion, y_pred_4_all_confusion)\n","\n","sns.heatmap(cm_4, annot=True, cmap='Blues')\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","plt.title('Confusion matrix Pipeline 4')\n","plt.show()\n","\n","# Pipeline 5\n","y_pred_5_all_con = [arr.tolist() for arr in y_pred_5_all]\n","y_test_5_all_con = np.array(y_test_5_all)\n","y_pred_5_all_con = np.array(y_pred_5_all_con)\n","y_test_5_all_confusion = [item for sublist in y_test_5_all_con for item in sublist]\n","y_pred_5_all_confusion = [item for sublist in y_pred_5_all_con for item in sublist]\n","\n","cm_5 = confusion_matrix(y_test_5_all_confusion, y_pred_5_all_confusion)\n","\n","sns.heatmap(cm_5, annot=True, cmap='Blues')\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","plt.title('Confusion matrix Pipeline 5')\n","plt.show()\n","\n","# Pipeline 6\n","y_pred_6_all_con = [arr.tolist() for arr in y_pred_6_all]\n","y_test_6_all_con = np.array(y_test_6_all)\n","y_pred_6_all_con = np.array(y_pred_6_all_con)\n","y_test_6_all_confusion = [item for sublist in y_test_6_all_con for item in sublist]\n","y_pred_6_all_confusion = [item for sublist in y_pred_6_all_con for item in sublist]\n","\n","cm_6 = confusion_matrix(y_test_6_all_confusion, y_pred_6_all_confusion)\n","\n","sns.heatmap(cm_6, annot=True, cmap='Blues')\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","plt.title('Confusion matrix Pipeline 6')\n","plt.show()\n","\n","# # Pipeline 7\n","# y_pred_7_all_con = [arr.tolist() for arr in y_pred_7_all]\n","# y_test_7_all_con = np.array(y_test_7_all)\n","# y_pred_7_all_con = np.array(y_pred_7_all_con)\n","# y_test_7_all_confusion = [item for sublist in y_test_7_all_con for item in sublist]\n","# y_pred_7_all_confusion = [item for sublist in y_pred_7_all_con for item in sublist]\n","\n","# cm_7 = confusion_matrix(y_test_7_all_confusion, y_pred_7_all_confusion)\n","\n","# sns.heatmap(cm_7, annot=True, cmap='Blues')\n","# plt.xlabel('Predicted labels')\n","# plt.ylabel('True labels')\n","# plt.title('Confusion matrix Pipeline 7')\n","# plt.show()\n","\n","# Classification reports\n","print(classification_report(y_test_1_all_confusion, y_pred_1_all_confusion))\n","print(classification_report(y_test_2_all_confusion, y_pred_2_all_confusion))\n","print(classification_report(y_test_3_all_confusion, y_pred_3_all_confusion))\n","print(classification_report(y_test_4_all_confusion, y_pred_4_all_confusion))\n","print(classification_report(y_test_5_all_confusion, y_pred_5_all_confusion))\n","print(classification_report(y_test_6_all_confusion, y_pred_6_all_confusion))\n","# print(classification_report(y_test_7_all_confusion, y_pred_7_all_confusion))"],"metadata":{"id":"ZhsH4Zllyrk_"},"execution_count":null,"outputs":[]}]}