{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TM10007 Assignment template -- ECG data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\ellem\\miniconda3\\lib\\site-packages (0.0.post1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ellem\\miniconda3\\lib\\site-packages (1.23.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ellem\\miniconda3\\lib\\site-packages (3.6.2)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\ellem\\miniconda3\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\ellem\\miniconda3\\lib\\site-packages (0.13.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ellem\\miniconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\ellem\\miniconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ellem\\miniconda3\\lib\\site-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ellem\\miniconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ellem\\miniconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ellem\\miniconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ellem\\miniconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ellem\\miniconda3\\lib\\site-packages (from matplotlib) (22.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\ellem\\miniconda3\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\ellem\\miniconda3\\lib\\site-packages (from imbalanced-learn) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ellem\\miniconda3\\lib\\site-packages (from imbalanced-learn) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ellem\\miniconda3\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\ellem\\miniconda3\\lib\\site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\ellem\\miniconda3\\lib\\site-packages (from statsmodels) (1.5.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ellem\\miniconda3\\lib\\site-packages (from pandas>=0.25->statsmodels) (2022.7)\n",
      "Requirement already satisfied: six in c:\\users\\ellem\\miniconda3\\lib\\site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install sklearn numpy matplotlib imbalanced-learn statsmodels\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels\n",
    "import seaborn\n",
    "import warnings\n",
    "import statistics\n",
    "\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from scipy.stats import shapiro, lognorm, randint\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, learning_curve, GridSearchCV, StratifiedKFold, cross_val_score, KFold, train_test_split, RandomizedSearchCV, validation_curve #, multipletests\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn import datasets as ds, model_selection, metrics, neighbors\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif, SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# Required and still not used:\n",
    "#import torch\n",
    "#import seaborn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd() # This fn will return the Current Working Directory\n",
    "\n",
    "zip_path = os.path.join(cwd, 'ecg', 'ecg_data.zip')\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(os.path.join(cwd, 'ecg'))\n",
    "\n",
    "data_path = os.path.join(cwd, 'ecg', 'ecg_data.csv')\n",
    "data = pd.read_csv(data_path, index_col=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 200)\n",
      "(50,)\n",
      "9 people have an abnormal ECG\n",
      "41 people have a normal ECG\n",
      "The percentage of abnormal ECGs in this dataset is 18.0 %\n"
     ]
    }
   ],
   "source": [
    "# split labels from data\n",
    "X = data.loc[:, data.columns != 'label']  #alles behalve label\n",
    "y = data['label']  # labels\n",
    "\n",
    "X = X.iloc[:50, :200]\n",
    "y = y.iloc[:50]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# normal / abnormal ECGs\n",
    "total_abnormal_ECG = np.count_nonzero(y) \n",
    "total_normal_ECG = y.size -np.count_nonzero(y) \n",
    "percentage_abnormal = total_abnormal_ECG / (total_abnormal_ECG + total_normal_ECG)*100\n",
    "\n",
    "print(f'{total_abnormal_ECG} people have an abnormal ECG')\n",
    "print(f'{total_normal_ECG} people have a normal ECG')\n",
    "print(f'The percentage of abnormal ECGs in this dataset is {percentage_abnormal} %')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data\n",
    "- Removing features if there is lot of data missing (replace all for a value)\n",
    "- Removing samples (in this case patients) if there is a lot of data missing\n",
    "- Imputation for generating data to fill us missing values -> median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing data\n",
    "X = X.replace(0, np.nan)  # make all zeros to NaN\n",
    "nan_count = X.isna().sum().sum()  # count missing data -> 10500 in our dataset\n",
    "\n",
    "# Delete missing data when > --% of feature of sample is missing\n",
    "X = X.dropna(axis='columns', how='all') # deletes a feature if all values of a column (so feature) are empty\n",
    "X = X.dropna(axis='rows', how='all') # deletes a patient if all values of a row (so sample) are empty\n",
    "\n",
    "# Missing data to median per feature\n",
    "for column in X.columns:\n",
    "    X[column].fillna(X[column].median(), inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for normal distribution - before outliers and missing data correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median p-value 0.0 Mean p-value 8.56094515530035e-27\n"
     ]
    }
   ],
   "source": [
    "# Normally distributed\n",
    "stat = []\n",
    "p = []\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'float64' or X[col].dtype == 'int64':\n",
    "        s, pv = shapiro(X[col])\n",
    "        stat.append(s)\n",
    "        p.append(pv)\n",
    "    else:\n",
    "        stat.append(None)\n",
    "        p.append(None)\n",
    "print('Median p-value', statistics.median(p), 'Mean p-value', statistics.mean(p))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "- Detect outliers using Z-score since data is not nornally distributed\n",
    "- Replace outliers by the median of that feature\n",
    "- Print -> check wether the outliers are changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of outliers in dataset x is 452774\n"
     ]
    }
   ],
   "source": [
    "# supress performance warning\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# Outliers: Tukey's fence \n",
    "k=3\n",
    "fences=pd.DataFrame()\n",
    "outliers = pd.DataFrame(False, index=X.index, columns=X.columns) # create an empty DataFrame for outliers\n",
    "\n",
    "for col in X.columns:\n",
    "    q1, q3 = np.percentile(X[col], [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower_fence = q1 - k*iqr\n",
    "    upper_fence = q3 + k*iqr\n",
    "    fences[col]=[lower_fence, upper_fence]\n",
    "    for row in X.index:\n",
    "        if X.loc[row, col] < lower_fence or X.loc[row, col] > upper_fence:\n",
    "            outliers.loc[row, col] = True # mark the place as an outlier\n",
    "\n",
    "row_count = (outliers == True).sum(axis=1)\n",
    "col_count = (outliers == True).sum(axis=0)\n",
    "total_count = row_count.sum() + col_count.sum()\n",
    "print(f'The total number of outliers in dataset x is {total_count}')\n",
    "\n",
    "# create a copy of x to modify\n",
    "new_x = X.copy()\n",
    "\n",
    "#replace outliers with maximum or minimun interquartile range of x by column\n",
    "for col in outliers.columns:\n",
    "    q3 = X.loc[outliers[col] == False, col].quantile(0.75) # 3rd quartile of column where outlier is False\n",
    "    q1 = X.loc[outliers[col] == False, col].quantile(0.25) # 1st quartile of column where outlier is False\n",
    "    iqr = q3 - q1 # interquartile range of column where outlier is False\n",
    "    lower_fence = q1 - k*iqr\n",
    "    upper_fence = q3 + k*iqr\n",
    "    new_x.loc[outliers[col] & (new_x[col] > upper_fence), col] = upper_fence # replace outliers with upper fence\n",
    "    new_x.loc[outliers[col] & (new_x[col] < lower_fence), col] = lower_fence # replace outliers with lower fence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing again for normal distribution - after outliers and missing data correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median p-value after preprocessing 6.3930750984386045e-28 Mean p-value after preprocessing 2.4986919776638156e-24\n"
     ]
    }
   ],
   "source": [
    "# Normally distributed\n",
    "stat = []\n",
    "p = []\n",
    "for col in new_x.columns:\n",
    "    if new_x[col].dtype == 'float64' or new_x[col].dtype == 'int64':\n",
    "        s, pv = shapiro(new_x[col])\n",
    "        stat.append(s)\n",
    "        p.append(pv)\n",
    "    else:\n",
    "        stat.append(None)\n",
    "        p.append(None)\n",
    "print('Median p-value after preprocessing', statistics.median(p), 'Mean p-value after preprocessing', statistics.mean(p))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIPELINE 1\n",
    "- RobustScaler --> PCA + univariate --> Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPELINE 1\n",
    "# Define outer and inner cross validation\n",
    "outer_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42) # to do: in discussie zetten waarom loopen nog beter zou zijn voor generaliseren\n",
    "inner_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42) \n",
    "\n",
    "best_auc_train_1 = []\n",
    "best_auc_test_1 = []\n",
    "best_hp_1 = pd.DataFrame()\n",
    "\n",
    "for train_index, test_index in outer_cv.split(X, y): \n",
    "    X_train = X.transpose()[train_index]\n",
    "    X_train = X_train.transpose()\n",
    "    # print(X_train.shape) # print size of X_train\n",
    "    y_train = y[train_index]\n",
    "    \n",
    "    X_test = X.transpose()[test_index]\n",
    "    X_test = X_test.transpose()\n",
    "    y_test = y[test_index]\n",
    "    # print(X_test.shape)     # print size of X_test\n",
    "\n",
    "    # balance the classes, so training set consists of 50% normal and 50% abnormal ECG's\n",
    "    ros = RandomOverSampler(sampling_strategy='minority')\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    X_train = X_resampled\n",
    "    y_train = y_resampled   \n",
    "\n",
    "    ## PIPELINE 1: RobustScaler --> PCA + univariate --> Gaussian Naive Bayes\n",
    "    # Define pipeline 1\n",
    "    pipeline_1 = Pipeline([\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('var_threshold', VarianceThreshold(threshold=0.0)),\n",
    "        ('pca', PCA()),\n",
    "        ('univar_feat_sel', SelectKBest(f_classif)),\n",
    "        ('clf', GaussianNB())\n",
    "    ])\n",
    "    # Define hyperparameters of pipeline 3\n",
    "    param_grid = {\n",
    "    'pca__n_components': [0.5,0.75, 0.9, 0.95, 0.99],\n",
    "    'univar_feat_sel__k': ['all'],\n",
    "    'clf__var_smoothing': np.logspace(0,-9, num=100),\n",
    "    }\n",
    "\n",
    "    # Perform grid search with inner cross-validation, part 1\n",
    "    rand_search = RandomizedSearchCV(pipeline_1, param_distributions=param_grid, n_iter=50, cv=inner_cv, scoring='roc_auc', n_jobs=-1) #klopt n__iter\n",
    "    rand_search.fit(X_train, y_train)\n",
    "\n",
    "    # Storing the best hyperparameters of each outer-CV loop in a DataFrame\n",
    "    # best_hp_1 = pd.DataFrame(columns=param_grid.keys())\n",
    "    best_hp_1 = best_hp_1.append(rand_search.best_params_,ignore_index=True)\n",
    "    \n",
    "    # Print the best hyperparameters and score\n",
    "    # print('Best hyperparameters after randomized search:', rand_search.best_params_)\n",
    "    # print('Best score after randomized search:', rand_search.best_score_)\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components = rand_search.best_params_['pca__n_components'])\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    # print(f'Size of X_Train after PCA {X_train.shape}')\n",
    "\n",
    "    # Get the selected feature indices from the univariate feature selection\n",
    "    sel_kb = SelectKBest(f_classif, k='all')\n",
    "    sel_kb.fit(X_train, y_train)\n",
    "    p_values = sel_kb.pvalues_\n",
    "\n",
    "    reject_fdr, pvals_fdr, _, _ = multipletests(pvals=p_values, alpha=0.05, method='fdr_bh')\n",
    "    features_selected=np.array(np.where(reject_fdr)[0])\n",
    "    # print(f'Size of selected features {features_selected.shape}')\n",
    "\n",
    "    # Apply univariate feature selection on X_train\n",
    "    # print(f'This is the size of X_train before univariate: {X_train.shape}')\n",
    "    X_train = X_train[:, features_selected]\n",
    "    # print(f'This is the size of X_train after univariate: {X_train.shape}')\n",
    "\n",
    "    # Train the classifier on the selected features with the best hyperparameters to create best trained classifier\n",
    "    clf_1 = GaussianNB(var_smoothing=rand_search.best_params_['clf__var_smoothing'])\n",
    "    clf_1.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf_1.predict(X_train)\n",
    "\n",
    "    if hasattr(clf_1, 'predict_proba'):\n",
    "    # The first column gives the probability for class = 0, so we take\n",
    "    # the second which gives the probability class = 1:\n",
    "        y_score = clf_1.predict_proba(X_train)[:, 1]\n",
    "    else:\n",
    "        y_score = y_pred\n",
    "\n",
    "    auc_train_1 = metrics.roc_auc_score(y_train, y_score)\n",
    "    # Storing the AUC train values of each outer CV loop\n",
    "    best_auc_train_1.append(auc_train_1)\n",
    "    \n",
    "    # print(f'The auc of the training data is {auc_train_1}')\n",
    "    # cv results\n",
    "    #pd.DataFrame(grid_nb.cv_results_)\n",
    "\n",
    "    # Evaluate the classifier on the test data\n",
    "    X_test = pca.transform(X_test)  # Apply the PCA transformation to the test data\n",
    "    X_test = X_test[:, features_selected]  # Apply the feature selection to the PCA-transformed test data\n",
    "    y_pred = clf_1.predict(X_test)\n",
    "    auc_test_1 = metrics.roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    best_auc_test_1.append(auc_test_1)\n",
    "     # print(f'The auc of the test data is {auc_test_1}')\n",
    "\n",
    "print(f'The  optimal hyperparameters per split:')\n",
    "best_hp_1\n",
    "print(f'The training AUCs of the nested cv {best_auc_train_1}')\n",
    "print(f'The test AUCs of the nested cv {best_auc_test_1}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIPELINE 2\n",
    "- PCA-Uni --> Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPELINE 2\n",
    "# Define outer and inner cross validation\n",
    "outer_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42) # to do: in discussie zetten waarom loopen nog beter zou zijn voor generaliseren\n",
    "inner_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "best_auc_train_2 = []\n",
    "best_auc_test_2= []\n",
    "best_hp_2 = pd.DataFrame()\n",
    "\n",
    "for train_index, test_index in outer_cv.split(X, y): \n",
    "    X_train = X.transpose()[train_index]\n",
    "    X_train = X_train.transpose()\n",
    "    # print(X_train.shape)\n",
    "    # print size of X_train\n",
    "    y_train = y[train_index]\n",
    "    \n",
    "    X_test = X.transpose()[test_index]\n",
    "    X_test = X_test.transpose()\n",
    "    y_test = y[test_index]\n",
    "    # print size of X_test\n",
    "    # print(X_test.shape)\n",
    "\n",
    "    # balance the classes, so training set consists of 50% normal and 50% abnormal ECG's\n",
    "    ros = RandomOverSampler(sampling_strategy='minority')\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    X_train = X_resampled\n",
    "    # print(f'Size of X_train after resampling {X_train.shape}')\n",
    "    y_train = y_resampled   \n",
    "\n",
    "    ## PIPELINE 2: RobustScaler --> PCA + univariate --> Quadratic Discriminant\n",
    "    # Define pipeline 2\n",
    "    pipeline_2 = Pipeline([\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('var_threshold', VarianceThreshold(threshold=0.0)),\n",
    "        ('pca', PCA()),\n",
    "        ('univar_feat_sel', SelectKBest(f_classif)),\n",
    "        ('clf', QuadraticDiscriminantAnalysis())\n",
    "    ])\n",
    "    # Define hyperparameters of pipeline 3\n",
    "    param_grid = {\n",
    "    'pca__n_components': [0.5,0.75,0.9,0.95,0.99],\n",
    "    'univar_feat_sel__k': ['all']\n",
    "    }\n",
    "\n",
    "    # Perform grid search with inner cross-validation, part 1\n",
    "    rand_search = RandomizedSearchCV(pipeline_2, param_distributions=param_grid,n_iter = 50, cv=inner_cv, scoring='roc_auc', n_jobs=-1) # optimize parameters\n",
    "    rand_search.fit(X_train, y_train)\n",
    "\n",
    "    # Storing the best hyperparameters of each outer-CV loop in a DataFrame\n",
    "    best_hp_2 = best_hp_2.append(rand_search.best_params_,ignore_index=True)\n",
    "\n",
    "    # Print the best hyperparameters and score\n",
    "    # print('Best hyperparameters after first grid search:', rand_search.best_params_)\n",
    "    # print('Best score after first grid search:', rand_search.best_score_)\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components = rand_search.best_params_['pca__n_components'])\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    # print(f'Size of X_train after PCA {X_train.shape}')\n",
    "\n",
    "    # Get the selected feature indices from the univariate feature selection\n",
    "    sel_kb = SelectKBest(f_classif, k='all')\n",
    "    sel_kb.fit(X_train, y_train)\n",
    "    p_values = sel_kb.pvalues_\n",
    "\n",
    "    reject_fdr, pvals_fdr, _, _ = multipletests(pvals=p_values, alpha=0.05, method='fdr_bh')\n",
    "    features_selected=np.array(np.where(reject_fdr)[0])\n",
    "    # print(f'Size of selected features {features_selected.shape}')\n",
    "    \n",
    "    # Apply univariate feature selection on X_train\n",
    "    # print(f'This is the size of X_train before univariate: {X_train.shape}')\n",
    "    X_train = X_train[:, features_selected]\n",
    "    # print(f'This is the size of X_train after univariate: {X_train.shape}')\n",
    "\n",
    "    # Train the classifier on the selected features with the best hyperparameters to create best trained classifier\n",
    "    clf_2 = QuadraticDiscriminantAnalysis()\n",
    "    clf_2.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf_2.predict(X_train)\n",
    "\n",
    "    if hasattr(clf_2, 'predict_proba'):\n",
    "    # The first column gives the probability for class = 0, so we take\n",
    "    # the second which gives the probability class = 1:\n",
    "        y_score = clf_2.predict_proba(X_train)[:, 1]\n",
    "    else:\n",
    "        y_score = y_pred\n",
    "\n",
    "    auc_train_2 = metrics.roc_auc_score(y_train, y_score)\n",
    "    # Storing the AUC train values of each outer CV loop\n",
    "    best_auc_train_2.append(auc_train_2)\n",
    "\n",
    "    # cv results\n",
    "    #pd.DataFrame(grid_nb.cv_results_)\n",
    "\n",
    "    # Evaluate the classifier on the test data\n",
    "    X_test = pca.transform(X_test)  # Apply the PCA transformation to the test data\n",
    "    X_test = X_test[:, features_selected]  # Apply the feature selection to the PCA-transformed test data\n",
    "    y_pred = clf_2.predict(X_test)\n",
    "    auc_test_2 = metrics.roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    # Storing the AUC test values of each outer CV loop\n",
    "    best_auc_test_2.append(auc_test_2)\n",
    "\n",
    "print(f'The  optimal hyperparameters per split:')\n",
    "best_hp_2\n",
    "print(f'The training AUcs of the nested cv {best_auc_train_2}')\n",
    "print(f'The test AUCs of the nested cv {best_auc_test_2}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIPELINE 3\n",
    "- RobustScaler --> PCA + univariate --> SVM_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPELINE 3\n",
    "# Define outer and inner cross validation\n",
    "outer_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42) # to do: in discussie zetten waarom loopen nog beter zou zijn voor generaliseren\n",
    "inner_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "best_hp_3 = pd.DataFrame()\n",
    "best_auc_train_3 = []\n",
    "best_auc_test_3= []\n",
    "\n",
    "for train_index, test_index in outer_cv.split(X, y): \n",
    "    X_train = X.transpose()[train_index]\n",
    "    X_train = X_train.transpose()\n",
    "    print(X_train.shape) # print size of X_train\n",
    "    y_train = y[train_index]\n",
    "    \n",
    "    X_test = X.transpose()[test_index]\n",
    "    X_test = X_test.transpose()\n",
    "    # print(X_test.shape) # print size of X_test\n",
    "    y_test = y[test_index]\n",
    "    \n",
    "\n",
    "    # balance the classes, so training set consists of 50% normal and 50% abnormal ECG's\n",
    "    ros = RandomOverSampler(sampling_strategy='minority')\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    X_train = X_resampled\n",
    "    y_train = y_resampled   \n",
    "\n",
    "    ## PIPELINE 3: RobustScaler --> PCA + univariate --> SVM_linear\n",
    "    # Define pipeline 3\n",
    "    pipeline_3 = Pipeline([\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('var_threshold', VarianceThreshold(threshold=0.0)),\n",
    "        ('pca', PCA()),\n",
    "        ('univar_feat_sel', SelectKBest(f_classif)),\n",
    "        ('clf', SVC())\n",
    "    ])\n",
    "    # Define hyperparameters of pipeline 2\n",
    "    param_grid = {\n",
    "    'pca__n_components': [0.5,0.75,0.9, 0.95, 0.99],\n",
    "    'univar_feat_sel__k': [ 'all'],\n",
    "    'clf__C': np.logspace(-3, 1, 20),\n",
    "    'clf__kernel': ['linear']\n",
    "    }\n",
    "\n",
    "    # Perform grid search with inner cross-validation, part 1\n",
    "    rand_search = RandomizedSearchCV(pipeline_3, param_distributions=param_grid, cv=inner_cv, scoring='roc_auc', n_jobs=-1) # optimize parameters\n",
    "    rand_search.fit(X_train, y_train)\n",
    "\n",
    "    # Storing the best hyperparameters of each outer-CV loop in a DataFrame\n",
    "    best_hp_3 = best_hp_3.append(rand_search.best_params_,ignore_index=True)\n",
    "\n",
    "    # Print the best hyperparameters and score\n",
    "    # print('Best hyperparameters after first grid search:', rand_search.best_params_)\n",
    "    # print('Best score after first grid search:', rand_search.best_score_)\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components = rand_search.best_params_['pca__n_components'])\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    # print(f'Size of X_Train after PC {X_train.shape}')\n",
    "\n",
    "    # Get the selected feature indices from the univariate feature selection\n",
    "    sel_kb = SelectKBest(f_classif, k='all')\n",
    "    sel_kb.fit(X_train, y_train)\n",
    "    p_values = sel_kb.pvalues_\n",
    "\n",
    "    reject_fdr, pvals_fdr, _, _ = multipletests(pvals=p_values, alpha=0.05, method='fdr_bh')\n",
    "    features_selected=np.array(np.where(reject_fdr)[0])\n",
    "    # print(f'Size of selected features {features_selected.shape}')\n",
    "\n",
    "    # Apply univariate feature selection on X_train\n",
    "    # print(f'This is the size of X_train before univariate: {X_train.shape}')\n",
    "    X_train = X_train[:, features_selected]\n",
    "    # print(f'This is the size of X_train after univariate: {X_train.shape}')\n",
    "\n",
    "    # Train the classifier on the selected features with the best hyperparameters to create best trained classifier\n",
    "    clf_3 = SVC(C=rand_search.best_params_['clf__C'], kernel=rand_search.best_params_['clf__kernel'])\n",
    "    clf_3.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf_3.predict(X_train)\n",
    "\n",
    "    if hasattr(clf_3, 'predict_proba'):\n",
    "    # The first column gives the probability for class = 0, so we take\n",
    "    # the second which gives the probability class = 1:\n",
    "        y_score = clf_3.predict_proba(X_train)[:, 1]\n",
    "    else:\n",
    "        y_score = y_pred\n",
    "\n",
    "    auc_train_3 = metrics.roc_auc_score(y_train, y_score)\n",
    "    # Storing the AUC train values of each outer CV loop\n",
    "    best_auc_train_3.append(auc_train_3)\n",
    "\n",
    "    # cv results\n",
    "    #pd.DataFrame(grid_nb.cv_results_)\n",
    "\n",
    "    # Evaluate the classifier on the test data\n",
    "    X_test = pca.transform(X_test)  # Apply the PCA transformation to the test data\n",
    "    X_test = X_test[:, features_selected]  # Apply the feature selection to the PCA-transformed test data\n",
    "    y_pred = clf_3.predict(X_test)\n",
    "    auc_test_3 = metrics.roc_auc_score(y_test, y_pred)\n",
    "    # Storing the AUC test values of each outer CV loop\n",
    "    best_auc_test_3.append(auc_test_3)\n",
    "\n",
    "print(f'The  optimal hyperparameters per split {best_hp_3}')\n",
    "print(f'The training AUcs of the nested cv {best_auc_train_3}')\n",
    "print(f'The test AUCs of the nested cv {best_auc_test_3}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIPELINE 4\n",
    "- PCA-UNI --> KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPELINE 4\n",
    "# Define outer and inner cross validation\n",
    "outer_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42) # to do: in discussie zetten waarom loopen nog beter zou zijn voor generaliseren\n",
    "inner_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "best_auc_train_4 = []\n",
    "best_auc_test_4= []\n",
    "best_hp_4 = pd.DataFrame()\n",
    "\n",
    "for train_index, test_index in outer_cv.split(X, y): \n",
    "    X_train = X.transpose()[train_index]\n",
    "    X_train = X_train.transpose()\n",
    "    # print(X_train.shape) # print size of X_train\n",
    "    y_train = y[train_index]\n",
    "    \n",
    "    X_test = X.transpose()[test_index]\n",
    "    X_test = X_test.transpose()\n",
    "    # print(X_test.shape) # print size of X_test\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    # balance the classes, so training set consists of 50% normal and 50% abnormal ECG's\n",
    "    ros = RandomOverSampler(sampling_strategy='minority')\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    X_train = X_resampled\n",
    "    # print(f'Size of X_train after resampling {X_train.shape}')\n",
    "    y_train = y_resampled   \n",
    "\n",
    "    ## PIPELINE 4: RobustScaler --> PCA + univariate --> KNN\n",
    "    # Define pipeline 4\n",
    "    pipeline_4 = Pipeline([\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('var_threshold', VarianceThreshold(threshold=0.0)),\n",
    "        ('pca', PCA()),\n",
    "        ('univar_feat_sel', SelectKBest(f_classif)),\n",
    "        ('clf', KNeighborsClassifier())\n",
    "    ])\n",
    "    # Define hyperparameters of pipeline 3\n",
    "    param_grid = {\n",
    "    'pca__n_components': [0.5,0.75,0.9,0.95,0.99],\n",
    "    'univar_feat_sel__k': ['all'],\n",
    "    'clf__n_neighbors': list(range(4,26,2)), # op 4 begonnen, want uit learning curves bleek dat \n",
    "    'clf__p': [1,2],\n",
    "    'clf__leaf_size': np.arange(1,26,1)\n",
    "    }\n",
    "\n",
    "    # Perform grid search with inner cross-validation, part 1\n",
    "    rand_search = RandomizedSearchCV(pipeline_4, param_distributions=param_grid, n_iter = 50, cv=inner_cv, scoring='roc_auc', n_jobs=-1) # optimize parameters\n",
    "    rand_search.fit(X_train, y_train)\n",
    "\n",
    "    # Storing the best hyperparameters of each outer-CV loop in a DataFrame\n",
    "    best_hp_4 = best_hp_4.append(rand_search.best_params_,ignore_index=True)\n",
    "\n",
    "    # Print the best hyperparameters and score\n",
    "    # print('Best hyperparameters after first grid search:', rand_search.best_params_)\n",
    "    # print('Best score after first grid search:', rand_search.best_score_)\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components = rand_search.best_params_['pca__n_components'])\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    # print(f'Size of X_Train after PC {X_train.shape}')\n",
    "\n",
    "    # Get the selected feature indices from the univariate feature selection\n",
    "    sel_kb = SelectKBest(f_classif, k='all')\n",
    "    sel_kb.fit(X_train, y_train)\n",
    "    p_values = sel_kb.pvalues_\n",
    "\n",
    "    reject_fdr, pvals_fdr, _, _ = multipletests(pvals=p_values, alpha=0.05, method='fdr_bh')\n",
    "    features_selected=np.array(np.where(reject_fdr)[0])\n",
    "    # print(f'Size of selected features {features_selected.shape}')\n",
    "    \n",
    "    # Apply univariate feature selection on X_train\n",
    "    # print(f'This is the size of X_train before univariate: {X_train.shape}')\n",
    "    X_train = X_train[:, features_selected]\n",
    "    # print(f'This is the size of X_train after univariate: {X_train.shape}')\n",
    "\n",
    "    # Train the classifier on the selected features with the best hyperparameters to create best trained classifier\n",
    "    clf_4 = KNeighborsClassifier(n_neighbors=rand_search.best_params_['clf__n_neighbors'], p=rand_search.best_params_['clf__p'], leaf_size=rand_search.best_params_['clf__leaf_size'])\n",
    "    clf_4.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf_4.predict(X_train)\n",
    "\n",
    "    if hasattr(clf_4, 'predict_proba'):\n",
    "    # The first column gives the probability for class = 0, so we take\n",
    "    # the second which gives the probability class = 1:\n",
    "        y_score = clf_4.predict_proba(X_train)[:, 1]\n",
    "    else:\n",
    "        y_score = y_pred\n",
    "\n",
    "    auc_train_4 = metrics.roc_auc_score(y_train, y_score)\n",
    "    # Storing the AUC train values of each outer CV loop\n",
    "    best_auc_train_4.append(auc_train_4)\n",
    "\n",
    "    # cv results\n",
    "    #pd.DataFrame(grid_nb.cv_results_)\n",
    "\n",
    "    # Evaluate the classifier on the test data\n",
    "    X_test = pca.transform(X_test)  # Apply the PCA transformation to the test data\n",
    "    X_test = X_test[:, features_selected]  # Apply the feature selection to the PCA-transformed test data\n",
    "    y_pred = clf_4.predict(X_test)\n",
    "    auc_test_4 = metrics.roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    # Storing the AUC test values of each outer CV loop\n",
    "    best_auc_test_4.append(auc_test_4)\n",
    "\n",
    "print(f'The  optimal hyperparameters per split: {best_hp_4}')\n",
    "print(f'The training AUcs of the nested cv {best_auc_train_4}')\n",
    "print(f'The test AUCs of the nested cv {best_auc_test_4}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIPELINE 5 \n",
    "- LASSO --> KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPELINE 5\n",
    "\n",
    "# Define outer and inner cross validation\n",
    "outer_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42) # to do: in discussie zetten waarom loopen nog beter zou zijn voor generaliseren\n",
    "inner_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "best_auc_train_5 = []\n",
    "best_auc_test_5= []\n",
    "best_hp_5 = pd.DataFrame()\n",
    "\n",
    "for train_index, test_index in outer_cv.split(X, y): \n",
    "    X_train = X.transpose()[train_index]\n",
    "    X_train = X_train.transpose()\n",
    "    # print(X_train.shape) # print size of X_train\n",
    "    y_train = y[train_index]\n",
    "\n",
    "    X_test = X.transpose()[test_index]\n",
    "    X_test = X_test.transpose()\n",
    "    # print(X_test.shape) # print size of X_test\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    # balance the classes, so training set consists of 50% normal and 50% abnormal ECG's\n",
    "    ros = RandomOverSampler(sampling_strategy='minority')\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    X_train = X_resampled\n",
    "    # print(f'Size of X_train after resampling {X_train.shape}')\n",
    "    y_train = y_resampled   \n",
    "\n",
    "    ## PIPELINE 5: RobustScaler --> LASSO --> KNN\n",
    "    # Define pipeline 5\n",
    "    pipeline_5a = Pipeline([\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('var_threshold', VarianceThreshold(threshold=0.0)),\n",
    "        ('lasso', Lasso()),\n",
    "    ])\n",
    "    # Define hyperparameters of pipeline 5\n",
    "    param_grid = {\n",
    "    'lasso__alpha': np.logspace(-10, 1, 100),\n",
    "    }\n",
    "\n",
    "    # Perform randomized search with inner cross-validation to find best alpha\n",
    "    rand_search = RandomizedSearchCV(pipeline_5a, param_distributions=param_grid, n_iter = 50, cv=inner_cv, scoring='roc_auc',n_jobs=-1) # optimize parameters\n",
    "    rand_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best hyperparameters and score\n",
    "    # print(f'Best hyperparameters after first randomized search: {rand_search.best_params_}')\n",
    "    # print(f'Best score after first randomized search: {rand_search.best_score_}')\n",
    "    \n",
    "    # print(f'This is the size of X_train before LASSO: {X_train.shape}')\n",
    "    # Create a new Lasso model using the best alpha value\n",
    "    lasso = Lasso(alpha=rand_search.best_params_['lasso__alpha'])\n",
    "    lasso.fit(X_train, y_train)\n",
    "\n",
    "    # Get the coefficients of the Lasso model, find them and define the new X_train with less features\n",
    "    coef = lasso.coef_\n",
    "    selected_features = np.where(coef != 0)[0]\n",
    "    X_train = X_train.iloc[:, selected_features]\n",
    "    # print(f'This is the size of X_train after LASSO: {X_train.shape}')\n",
    "\n",
    "    # pipeline 5.b\n",
    "    pipeline_5b = Pipeline([\n",
    "        ('clf', KNeighborsClassifier())\n",
    "    ])\n",
    "    # Define hyperparameters of pipeline 5b\n",
    "    param_grid = {\n",
    "    'clf__n_neighbors': list(range(4,26,2)),\n",
    "    'clf__p': [1,2],\n",
    "    'clf__leaf_size': np.arange(1,26,1)\n",
    "    }\n",
    "\n",
    "    # Perform grid search with inner cross-validation, part 2\n",
    "    rand_search = RandomizedSearchCV(pipeline_5b, param_distributions=param_grid, n_iter = 50, cv=inner_cv, scoring='roc_auc', n_jobs=-1) # optimize parameters\n",
    "    rand_search.fit(X_train, y_train)\n",
    "\n",
    "    # Storing the best hyperparameters of each outer-CV loop in a DataFrame\n",
    "    best_hp_5 = best_hp_5.append(rand_search.best_params_,ignore_index=True)\n",
    "\n",
    "    # Print the best hyperparameters and score\n",
    "    # print(f'Best hyperparameters after second randomized search: {rand_search.best_params_}')\n",
    "    # print(f'Best score after second randomized search: {rand_search.best_score_}')\n",
    "\n",
    "    # Train the classifier on the selected features with the best hyperparameters to create best trained classifier\n",
    "    clf_5 = KNeighborsClassifier(n_neighbors=rand_search.best_params_['clf__n_neighbors'], p=rand_search.best_params_['clf__p'], leaf_size=rand_search.best_params_['clf__leaf_size'])\n",
    "    clf_5.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf_5.predict(X_train)\n",
    "\n",
    "    if hasattr(clf_5, 'predict_proba'):\n",
    "    # The first column gives the probability for class = 0, so we take\n",
    "    # the second which gives the probability class = 1:\n",
    "        y_score = clf_5.predict_proba(X_train)[:, 1]\n",
    "    else:\n",
    "        y_score = y_pred\n",
    "\n",
    "    auc_train_5 = metrics.roc_auc_score(y_train, y_score)\n",
    "    # Storing the AUC test values of each outer CV loop\n",
    "    best_auc_train_5.append(auc_train_5)\n",
    "   \n",
    "    # cv results\n",
    "    #pd.DataFrame(grid_nb.cv_results_)\n",
    "\n",
    "    # Evaluate the classifier on the test data\n",
    "    X_test = X_test.iloc[:, selected_features] # apply lasso feature reduction to X_test\n",
    "    # print(f'The size of X_test after applying lasso is {X_test.shape}')\n",
    "    y_pred = clf_5.predict(X_test)\n",
    "    auc_test_5 = metrics.roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Storing the AUC test values of each outer CV loop\n",
    "    best_auc_test_5.append(auc_test_5)\n",
    "\n",
    "print(f'The  optimal hyperparameters per split: {best_hp_5}')\n",
    "print(f'The training AUcs of the nested cv {best_auc_train_5}')\n",
    "print(f'The test AUCs of the nested cv {best_auc_test_5}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIPELINE 6\n",
    "- PCA-UNI --> Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "34 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "34 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 435, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.79888889 0.75              nan 0.86888889        nan 0.88666667\n",
      "        nan 0.94222222        nan 0.94444444 0.85333333 0.94888889\n",
      " 0.78555556        nan 0.71666667 0.91111111 0.79333333 0.91333333\n",
      "        nan 0.77111111 0.93777778 0.79666667 0.89333333        nan\n",
      " 0.91111111 0.83111111        nan        nan        nan 0.93555556\n",
      " 0.89111111 0.86888889        nan        nan 0.92888889 0.84777778\n",
      "        nan        nan 0.90222222        nan 0.85555556        nan\n",
      " 0.92888889 0.91777778 0.87333333 0.81444444 0.86888889 0.92\n",
      "        nan 0.93111111]\n",
      "  warnings.warn(\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:778: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "C:\\Users\\ellem\\AppData\\Local\\Temp\\ipykernel_31344\\2753387516.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_hp_6 = best_hp_6.append(rand_search.best_params_,ignore_index=True)\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:778: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "24 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 435, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.875             nan 0.95       0.68958333        nan        nan\n",
      " 0.91666667 0.89166667 0.86666667 0.90208333 0.9625     0.94583333\n",
      "        nan 0.92083333        nan 0.89583333 0.78333333 0.95\n",
      " 0.80416667 0.88958333 0.67604167 0.87916667 0.85416667 0.95625\n",
      " 0.79166667        nan 0.95833333 0.85416667        nan 0.90416667\n",
      " 0.925             nan 0.90416667 0.94166667 0.85625    0.5\n",
      " 0.5               nan 0.67916667 0.80416667        nan 0.575\n",
      " 0.5               nan 0.9625     0.8875     0.75833333        nan\n",
      " 0.5        0.95      ]\n",
      "  warnings.warn(\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:778: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "C:\\Users\\ellem\\AppData\\Local\\Temp\\ipykernel_31344\\2753387516.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_hp_6 = best_hp_6.append(rand_search.best_params_,ignore_index=True)\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:778: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "18 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 435, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.90416667        nan 0.675      0.74375           nan 0.92291667\n",
      " 0.73645833 0.628125   0.59479167        nan 0.58645833 0.77916667\n",
      " 0.875      0.94375    0.90208333        nan 0.64583333 0.68958333\n",
      " 0.74583333 0.71354167        nan        nan 0.83541667 0.82291667\n",
      " 0.86458333 0.93958333 0.98125    0.653125   0.80208333 0.89375\n",
      " 0.8375     0.83541667        nan 0.8875     0.975      0.85208333\n",
      "        nan 0.89583333 0.77916667 0.865625   0.95208333 0.89166667\n",
      " 0.94166667        nan 0.91458333 0.68541667 0.82916667 0.5\n",
      " 0.88125    0.68645833]\n",
      "  warnings.warn(\n",
      "C:\\Users\\ellem\\AppData\\Local\\Temp\\ipykernel_31344\\2753387516.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_hp_6 = best_hp_6.append(rand_search.best_params_,ignore_index=True)\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 435, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.925      0.89375    0.88020833        nan 0.89375           nan\n",
      "        nan        nan 0.71041667 0.80625    0.90208333 0.83020833\n",
      " 0.93541667 0.89375    0.91666667        nan        nan 0.81979167\n",
      " 0.875      0.91041667 0.90625    0.89166667 0.85833333 0.884375\n",
      "        nan        nan 0.89375    0.753125   0.86458333 0.92916667\n",
      " 0.89166667 0.71041667 0.85208333        nan 0.84895833 0.9125\n",
      " 0.88020833        nan        nan 0.75729167 0.88125           nan\n",
      "        nan        nan 0.84895833 0.64791667        nan 0.5\n",
      " 0.91666667 0.89166667]\n",
      "  warnings.warn(\n",
      "C:\\Users\\ellem\\AppData\\Local\\Temp\\ipykernel_31344\\2753387516.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_hp_6 = best_hp_6.append(rand_search.best_params_,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The  optimal hyperparameters per split:   univar_feat_sel__k  pca__n_components  clf__warm_start  clf__oob_score  \\\n",
      "0                all               0.90             True           False   \n",
      "1                all               0.90             True            True   \n",
      "2                all               0.99            False           False   \n",
      "3                all               0.95            False           False   \n",
      "\n",
      "   clf__n_estimators  clf__min_weight_fraction_leaf  clf__min_samples_split  \\\n",
      "0                130                         0.0000                       6   \n",
      "1                585                         0.0625                       7   \n",
      "2                635                         0.1875                       9   \n",
      "3                625                         0.1875                       8   \n",
      "\n",
      "   clf__min_samples_leaf clf__max_features clf__criterion clf__class_weight  \\\n",
      "0                      4              None           gini          balanced   \n",
      "1                      2              sqrt       log_loss          balanced   \n",
      "2                      2              sqrt        entropy          balanced   \n",
      "3                      1              log2           gini          balanced   \n",
      "\n",
      "   clf__bootstrap  \n",
      "0            True  \n",
      "1            True  \n",
      "2            True  \n",
      "3           False  \n",
      "The training AUcs of the nested cv [0.98, 0.9979188345473465, 0.9635796045785641, 0.9750260145681582]\n",
      "The test AUCs of the nested cv [0.5, 0.5833333333333333, 0.4, 0.45]\n"
     ]
    }
   ],
   "source": [
    "# PIPELINE 6\n",
    "# Define outer and inner cross validation\n",
    "outer_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42) # to do: in discussie zetten waarom loopen nog beter zou zijn voor generaliseren\n",
    "inner_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "best_auc_train_6 = []\n",
    "best_auc_test_6= []\n",
    "best_hp_6 = pd.DataFrame()\n",
    "\n",
    "for train_index, test_index in outer_cv.split(X, y): \n",
    "    X_train = X.transpose()[train_index]\n",
    "    X_train = X_train.transpose()\n",
    "    # print(X_train.shape) # print size of X_train\n",
    "    y_train = y[train_index]\n",
    "    \n",
    "    X_test = X.transpose()[test_index]\n",
    "    X_test = X_test.transpose()\n",
    "    # print(X_test.shape) # print size of X_test\n",
    "    y_test = y[test_index]\n",
    "    \n",
    "    \n",
    "\n",
    "    # balance the classes, so training set consists of 50% normal and 50% abnormal ECG's\n",
    "    ros = RandomOverSampler(sampling_strategy='minority')\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    X_train = X_resampled\n",
    "    # print(f'Size of X_train after resampling {X_train.shape}')\n",
    "    y_train = y_resampled   \n",
    "\n",
    "    ## PIPELINE 6: RobustScaler --> PCA + univariate --> RF\n",
    "    # Define pipeline 6\n",
    "    pipeline_6 = Pipeline([\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('var_threshold', VarianceThreshold(threshold=0.0)),\n",
    "        ('pca', PCA()),\n",
    "        ('univar_feat_sel', SelectKBest(f_classif)),\n",
    "        ('clf', RandomForestClassifier())])\n",
    "    \n",
    "    # Define hyperparameters of pipeline 6\n",
    "    param_distributions = {'pca__n_components': [0.5,0.75,0.9,0.95,0.99],\n",
    "                               'univar_feat_sel__k': ['all'],\n",
    "                               'clf__n_estimators' : range(5,1000,5),\n",
    "                               'clf__criterion' :['gini','entropy','log_loss'],\n",
    "                               'clf__min_samples_split':range(2,10),\n",
    "                               'clf__min_samples_leaf':range(1,10),\n",
    "                               'clf__min_weight_fraction_leaf' : np.linspace(0, 0.5, 25),\n",
    "                               'clf__max_features':['sqrt','log2',None],\n",
    "                               'clf__bootstrap':[True,False],\n",
    "                               'clf__oob_score':[True,False],\n",
    "                               'clf__warm_start':[True,False],\n",
    "                               'clf__class_weight':['balanced','balanced']}\n",
    "\n",
    "    # Perform grid search with inner cross-validation, part 1\n",
    "    rand_search = RandomizedSearchCV(pipeline_6, param_distributions=param_distributions, n_iter = 50, cv=inner_cv, scoring='roc_auc', n_jobs=-1) # optimize parameters\n",
    "    rand_search.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    # Storing the best hyperparameters of each outer-CV loop in a DataFrame\n",
    "    best_hp_6 = best_hp_6.append(rand_search.best_params_,ignore_index=True)\n",
    "\n",
    "    # Print the best hyperparameters and score\n",
    "    # print('Best hyperparameters after first grid search:', rand_search.best_params_)\n",
    "    # print('Best score after first grid search:', rand_search.best_score_)\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components = rand_search.best_params_['pca__n_components'])\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    # print(f'Size of X_Train after PC {X_train.shape}')\n",
    "\n",
    "    # Get the selected feature indices from the univariate feature selection\n",
    "    sel_kb = SelectKBest(f_classif, k='all')\n",
    "    sel_kb.fit(X_train, y_train)\n",
    "    p_values = sel_kb.pvalues_\n",
    "\n",
    "    reject_fdr, pvals_fdr, _, _ = multipletests(pvals=p_values, alpha=0.05, method='fdr_bh')\n",
    "    features_selected=np.array(np.where(reject_fdr)[0])\n",
    "    # print(f'Size of selected features {features_selected.shape}')\n",
    "    \n",
    "    # Apply univariate feature selection on X_train\n",
    "    # print(f'This is the size of X_train before univariate: {X_train.shape}')\n",
    "    X_train = X_train[:, features_selected]\n",
    "    # print(f'This is the size of X_train after univariate: {X_train.shape}')\n",
    "\n",
    "    # Train the classifier on the selected features with the best hyperparameters to create best trained classifier   \n",
    "    clf_6 = RandomForestClassifier(n_estimators=rand_search.best_params_['clf__n_estimators'], max_features=rand_search.best_params_['clf__max_features'], min_samples_split=rand_search.best_params_['clf__min_samples_split'], bootstrap=rand_search.best_params_['clf__bootstrap'], criterion=rand_search.best_params_['clf__criterion'], min_samples_leaf=rand_search.best_params_['clf__min_samples_leaf'], min_weight_fraction_leaf=rand_search.best_params_['clf__min_weight_fraction_leaf'], oob_score=rand_search.best_params_['clf__oob_score'],warm_start=rand_search.best_params_['clf__warm_start'],class_weight=rand_search.best_params_['clf__class_weight'])\n",
    "    clf_6.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf_6.predict(X_train)\n",
    "\n",
    "    if hasattr(clf_6, 'predict_proba'):\n",
    "    # The first column gives the probability for class = 0, so we take\n",
    "    # the second which gives the probability class = 1:\n",
    "        y_score = clf_6.predict_proba(X_train)[:, 1]\n",
    "    else:\n",
    "        y_score = y_pred\n",
    "\n",
    "    auc_train_6 = metrics.roc_auc_score(y_train, y_score)\n",
    "     # Storing the AUC test values of each outer CV loop\n",
    "    best_auc_train_6.append(auc_train_6)\n",
    "\n",
    "    # print(f'The auc of the training data is {auc}')\n",
    "    # cv results\n",
    "    #pd.DataFrame(grid_nb.cv_results_)\n",
    "\n",
    "    # Evaluate the classifier on the test data\n",
    "    X_test = pca.transform(X_test)  # Apply the PCA transformation to the test data\n",
    "    X_test = X_test[:, features_selected]  # Apply the feature selection to the PCA-transformed test data\n",
    "    y_pred = clf_6.predict(X_test)\n",
    "    auc_test_6 = metrics.roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    # Storing the AUC test values of each outer CV loop\n",
    "    best_auc_test_6.append(auc_test_6)\n",
    "\n",
    "print(f'The  optimal hyperparameters per split: {best_hp_6}')\n",
    "print(f'The training AUcs of the nested cv {best_auc_train_6}')\n",
    "print(f'The test AUCs of the nested cv {best_auc_test_6}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIPELINE 7\n",
    "- LASSO --> Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.630e-02, tolerance: 1.500e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "14 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "14 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 435, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.99555556 0.92666667 0.80222222 0.92444444 0.91777778        nan\n",
      " 0.94444444 1.         0.92       0.96666667 0.91555556 0.87555556\n",
      " 0.92666667 0.97777778 0.87111111 0.92444444 0.91777778        nan\n",
      " 0.93111111 0.98222222        nan 1.         0.92666667 0.94111111\n",
      "        nan 0.98222222 0.99111111 0.98222222 1.         0.93555556\n",
      " 0.94666667 0.76888889 0.88       0.97555556 0.80222222        nan\n",
      " 0.96666667 0.86888889 0.88       0.93555556 0.94888889 0.92444444\n",
      "        nan 0.89333333 1.         0.93555556        nan 0.91777778\n",
      " 0.96       1.        ]\n",
      "  warnings.warn(\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:778: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "C:\\Users\\ellem\\AppData\\Local\\Temp\\ipykernel_31344\\3479707509.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_hp_7 = best_hp_7.append(rand_search.best_params_,ignore_index=True)\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:778: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.223e-03, tolerance: 1.550e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "28 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "28 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 435, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.96875    0.98125    1.         0.96041667 1.         0.98125\n",
      " 0.95              nan 0.99375    0.95625    0.81979167 1.\n",
      "        nan 0.91666667        nan        nan        nan 1.\n",
      " 0.95208333 1.         0.96875    0.9375     0.5               nan\n",
      "        nan 1.                nan 0.96875           nan 0.81979167\n",
      " 0.95              nan 0.99375    0.99375           nan 0.93854167\n",
      "        nan        nan 1.         0.93125    0.96875           nan\n",
      " 0.81979167 0.9625     0.95625    0.9625     0.98125    0.9625\n",
      " 0.81979167 1.        ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\ellem\\AppData\\Local\\Temp\\ipykernel_31344\\3479707509.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_hp_7 = best_hp_7.append(rand_search.best_params_,ignore_index=True)\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.078e-03, tolerance: 1.550e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 435, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.75833333 0.83541667 0.83125    0.83125    0.8        0.76875\n",
      " 0.825      0.74375           nan 0.79583333        nan 0.81041667\n",
      "        nan 0.5875     0.80625    0.7625     0.82083333        nan\n",
      " 0.7875     0.7875     0.77291667 0.8375            nan        nan\n",
      " 0.82708333 0.82291667 0.8               nan        nan        nan\n",
      " 0.80625    0.75833333 0.603125   0.78541667 0.80625           nan\n",
      "        nan 0.7875            nan        nan 0.78125    0.77083333\n",
      " 0.825      0.82916667 0.79166667 0.8125            nan 0.72083333\n",
      " 0.72916667        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\ellem\\AppData\\Local\\Temp\\ipykernel_31344\\3479707509.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_hp_7 = best_hp_7.append(rand_search.best_params_,ignore_index=True)\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "32 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "32 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 435, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.95              nan 0.91875           nan 0.9375\n",
      " 0.9        0.925      0.9        0.95       0.93125    0.925\n",
      " 0.89166667 0.92708333        nan        nan 0.93333333 0.93333333\n",
      " 0.93333333        nan 0.93333333 0.94583333 0.92916667 0.9125\n",
      " 0.85729167 0.92916667 0.92083333        nan 0.92708333 0.9375\n",
      " 0.93541667        nan 0.94166667 0.94166667 0.92916667 0.92708333\n",
      " 0.92916667 0.94166667 0.95              nan        nan 0.925\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.5        0.94166667]\n",
      "  warnings.warn(\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:778: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "C:\\Users\\ellem\\AppData\\Local\\Temp\\ipykernel_31344\\3479707509.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  best_hp_7 = best_hp_7.append(rand_search.best_params_,ignore_index=True)\n",
      "c:\\Users\\ellem\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:778: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The  optimal hyperparameters per split:    clf__warm_start  clf__oob_score  clf__n_estimators  \\\n",
      "0             True           False                695   \n",
      "1            False           False                960   \n",
      "2            False           False                365   \n",
      "3             True           False                450   \n",
      "\n",
      "   clf__min_weight_fraction_leaf  clf__min_samples_split  \\\n",
      "0                       0.083333                       2   \n",
      "1                       0.041667                       8   \n",
      "2                       0.125000                       7   \n",
      "3                       0.125000                       2   \n",
      "\n",
      "   clf__min_samples_leaf clf__max_features clf__criterion clf__class_weight  \\\n",
      "0                      1              log2       log_loss          balanced   \n",
      "1                      7              log2       log_loss          balanced   \n",
      "2                      7              sqrt        entropy          balanced   \n",
      "3                      2              None       log_loss          balanced   \n",
      "\n",
      "   clf__bootstrap  \n",
      "0            True  \n",
      "1           False  \n",
      "2            True  \n",
      "3           False  \n",
      "The training AUcs of the nested cv [1.0, 1.0, 1.0, 0.985952133194589]\n",
      "The test AUCs of the nested cv [0.5, 0.5, 0.75, 0.5]\n"
     ]
    }
   ],
   "source": [
    "# Define outer and inner cross validation\n",
    "outer_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42) # to do: in discussie zetten waarom loopen nog beter zou zijn voor generaliseren\n",
    "inner_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "best_auc_train_7 = []\n",
    "best_auc_test_7= []\n",
    "best_hp_7 = pd.DataFrame()\n",
    "\n",
    "for train_index, test_index in outer_cv.split(X, y): \n",
    "    X_train = X.transpose()[train_index]\n",
    "    X_train = X_train.transpose()\n",
    "    # print(X_train.shape) # print size of X_train\n",
    "    y_train = y[train_index]\n",
    "\n",
    "    X_test = X.transpose()[test_index]\n",
    "    X_test = X_test.transpose()\n",
    "    # print(X_test.shape) # print size of X_test\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    # balance the classes, so training set consists of 50% normal and 50% abnormal ECG's\n",
    "    ros = RandomOverSampler(sampling_strategy='minority')\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    X_train = X_resampled\n",
    "    # print(f'Size of X_train after resampling {X_train.shape}')\n",
    "    y_train = y_resampled   \n",
    "\n",
    "    ## PIPELINE 7: RobustScaler --> LASSO --> RF\n",
    "    # Define pipeline 7\n",
    "    pipeline_7a = Pipeline([\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('lasso', Lasso()),\n",
    "    ])\n",
    "    # Define hyperparameters of pipeline 5\n",
    "    param_grid = {\n",
    "    'lasso__alpha': np.logspace(-10, 1, 100),\n",
    "    }\n",
    "\n",
    "    # Perform randomized search with inner cross-validation to find best alpha\n",
    "    rand_search = RandomizedSearchCV(pipeline_5a, param_distributions=param_grid, n_iter = 50, cv=inner_cv, scoring='roc_auc',n_jobs=-1) # optimize parameters\n",
    "    rand_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best hyperparameters and score\n",
    "    # print(f'Best hyperparameters after first randomized search: {rand_search.best_params_}')\n",
    "    # print(f'Best score after first randomized search: {rand_search.best_score_}')\n",
    "    \n",
    "    # print(f'This is the size of X_train before LASSO: {X_train.shape}')\n",
    "    # Create a new Lasso model using the best alpha value\n",
    "    lasso = Lasso(alpha=rand_search.best_params_['lasso__alpha'])\n",
    "    lasso.fit(X_train, y_train)\n",
    "\n",
    "    # Get the coefficients of the Lasso model, find them and define the new X_train with less features\n",
    "    coef = lasso.coef_\n",
    "    selected_features = np.where(coef != 0)[0]\n",
    "    X_train = X_train.iloc[:, selected_features]\n",
    "    # print(f'This is the size of X_train after LASSO: {X_train.shape}')\n",
    "\n",
    "## PIPELINE 7: RobustScaler --> LASSO --> RF\n",
    "    # Define pipeline 7\n",
    "    pipeline_7 = Pipeline([\n",
    "        ('clf', RandomForestClassifier())])\n",
    "    \n",
    "    # Define hyperparameters of pipeline 7\n",
    "    param_distributions = {'clf__n_estimators' : range(5,1000,5),\n",
    "                               'clf__criterion' :['gini','entropy','log_loss'],\n",
    "                               'clf__min_samples_split':range(2,10),\n",
    "                               'clf__min_samples_leaf':range(1,10),\n",
    "                               'clf__min_weight_fraction_leaf' : np.linspace(0, 0.5, 25),\n",
    "                               'clf__max_features':['sqrt','log2',None],\n",
    "                               'clf__bootstrap':[True,False],\n",
    "                               'clf__oob_score':[True,False],\n",
    "                               'clf__warm_start':[True,False],\n",
    "                               'clf__class_weight':['balanced','balanced']}\n",
    "\n",
    "    # Perform grid search with inner cross-validation, part 1\n",
    "    rand_search = RandomizedSearchCV(pipeline_7, param_distributions=param_distributions, n_iter = 50, cv=inner_cv, scoring='roc_auc', n_jobs=-1) # optimize parameters\n",
    "    rand_search.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    # Storing the best hyperparameters of each outer-CV loop in a DataFrame\n",
    "    best_hp_7 = best_hp_7.append(rand_search.best_params_,ignore_index=True)\n",
    "\n",
    "    # Print the best hyperparameters and score\n",
    "    # print('Best hyperparameters after first grid search:', rand_search.best_params_)\n",
    "    # print('Best score after first grid search:', rand_search.best_score_)\n",
    "\n",
    "    # Train the classifier on the selected features with the best hyperparameters to create best trained classifier   \n",
    "    clf_7 = RandomForestClassifier(n_estimators=rand_search.best_params_['clf__n_estimators'], max_features=rand_search.best_params_['clf__max_features'], min_samples_split=rand_search.best_params_['clf__min_samples_split'], bootstrap=rand_search.best_params_['clf__bootstrap'], criterion=rand_search.best_params_['clf__criterion'], min_samples_leaf=rand_search.best_params_['clf__min_samples_leaf'], min_weight_fraction_leaf=rand_search.best_params_['clf__min_weight_fraction_leaf'], oob_score=rand_search.best_params_['clf__oob_score'],warm_start=rand_search.best_params_['clf__warm_start'],class_weight=rand_search.best_params_['clf__class_weight'])\n",
    "    clf_7.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf_7.predict(X_train)\n",
    "\n",
    "    if hasattr(clf_7, 'predict_proba'):\n",
    "    # The first column gives the probability for class = 0, so we take\n",
    "    # the second which gives the probability class = 1:\n",
    "        y_score = clf_7.predict_proba(X_train)[:, 1]\n",
    "    else:\n",
    "        y_score = y_pred\n",
    "\n",
    "    auc_train_7 = metrics.roc_auc_score(y_train, y_score)\n",
    "     # Storing the AUC test values of each outer CV loop\n",
    "    best_auc_train_7.append(auc_train_7)\n",
    "\n",
    "    # print(f'The auc of the training data is {auc}')\n",
    "    # cv results\n",
    "    #pd.DataFrame(grid_nb.cv_results_)\n",
    "\n",
    "    # Evaluate the classifier on the test data\n",
    "    X_test = X_test.iloc[:, selected_features]  # Apply the feature selection to the PCA-transformed test data\n",
    "    y_pred = clf_7.predict(X_test)\n",
    "    auc_test_7 = metrics.roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    # Storing the AUC test values of each outer CV loop\n",
    "    best_auc_test_7.append(auc_test_7)\n",
    "\n",
    "print(f'The  optimal hyperparameters per split: {best_hp_7}')\n",
    "print(f'The training AUcs of the nested cv {best_auc_train_7}')\n",
    "print(f'The test AUCs of the nested cv {best_auc_test_7}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meuk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipelines\n",
    "#1\n",
    "def pipeline1(X_train, y_train, X_test, y_test):\n",
    "    # Preprocessing\n",
    "    scaler = RobustScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Variance Threshold\n",
    "    vt = VarianceThreshold(threshold=0.0)\n",
    "    X_train = vt.fit_transform(X_train)\n",
    "    X_test = vt.transform(X_test)\n",
    "\n",
    "    # PCA\n",
    "    n_samples = X_train.shape[0]\n",
    "    n_features = X_train.shape[1]\n",
    "    n_features = min(n_samples, n_features)\n",
    "    pca = PCA(n_components=n_features)\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.transform(X_test)\n",
    "\n",
    "    # Univariate selection\n",
    "    kb = SelectKBest(f_classif, k='all') # juiste code erin als af\n",
    "    X_train = kb.fit_transform(X_train, y_train)\n",
    "    p_values_train = kb.pvalues_\n",
    "    reject_fdr, pvals_fdr, _, _ = multipletests(pvals=p_values_train, alpha=0.05, method='fdr_bh')\n",
    "    features_selected_train = np.array(np.where(reject_fdr)[0])\n",
    "    print(features_selected_train.shape)\n",
    "    X_train = X_train[:,features_selected_train]\n",
    "\n",
    "    X_test = kb.transform(X_test)\n",
    "    p_values_test = kb.pvalues_\n",
    "    reject_fdr, pvals_fdr, _, _ = multipletests(pvals=p_values_test, alpha=0.05, method='fdr_bh')\n",
    "    features_selected_test = np.array(np.where(reject_fdr)[0])\n",
    "    print(features_selected_test.shape)\n",
    "    X_test = X_test[:,features_selected_test]\n",
    "\n",
    "    # KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    roc_auc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    return roc_auc_score\n",
    "\n",
    "def pipeline2(X_train, y_train, X_test, y_test, alpha=0.5, n_neighbors=5):\n",
    "    # Preprocessing\n",
    "    scaler = RobustScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Variance Threshold\n",
    "    vt = VarianceThreshold(threshold=0.0)\n",
    "    X_train = vt.fit_transform(X_train)\n",
    "    X_test = vt.transform(X_test)\n",
    "\n",
    "    # LASSO regularization\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    X_train = lasso.fit_transform(X_train, y_train)\n",
    "    X_test = lasso.transform(X_test)\n",
    "\n",
    "    # KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    roc_auc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    return roc_auc_score\n",
    "\n",
    "# Define the parameters for grid search\n",
    "param_grid1 = {\n",
    "    'n_pca': [], #doesn't have parameters that need grid_search\n",
    "    'k_features': [], #doesn't have parameters that need grid_search\n",
    "    'n_neighbors': list(range(1, 26, 2))\n",
    "}\n",
    "\n",
    "param_grid2 = {\n",
    "    'alpha': [np.logspace(-5, 1, 100)],\n",
    "    'n_neighbors': list(range(1, 26, 2))\n",
    "}\n",
    "\n",
    "# Define the outer and inner cross-validation\n",
    "outer_cv = StratifiedKFold(n_splits=4) #als we 4 splits doen, wordt de data in 25%/75% gesplit\n",
    "inner_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform the grid search using nested cross-validation\n",
    "best_scores1 = []\n",
    "best_scores2 = []\n",
    "\n",
    "best_n_neighbors = []\n",
    "results_1 = []\n",
    "results_2 = []\n",
    "\n",
    "for train_index, test_index in outer_cv.split(X, y): \n",
    "    X_train = X.transpose()[train_index]\n",
    "    X_train = X_train.transpose()\n",
    "    print(X_train.shape)\n",
    "    y_train = y[train_index]\n",
    "    \n",
    "    X_test = X.transpose()[test_index]\n",
    "    X_test = X_test.transpose()\n",
    "    y_test = y[test_index]\n",
    "    print(X_test.shape)\n",
    "\n",
    "    # Create a grid search to find the optimal k using a gridsearch and 10-fold cross validation\n",
    "#     grid_search1 = GridSearchCV(estimator=pipeline1, param_grid=param_grid1, cv=inner_cv, scoring='roc_auc') #error logisch, want pipeline1 is een functie\n",
    "#     grid_search1.fit(X_train, y_train)\n",
    "#     best_scores1.append(grid_search1.best_score_)\n",
    "\n",
    "#     grid_search2 = GridSearchCV(estimator=pipeline2, param_grid=param_grid2, cv=inner_cv, scoring='roc_auc')\n",
    "#     grid_search2.fit(X_train, y_train)\n",
    "#     best_scores2.append(grid_search2.best_score_)\n",
    "\n",
    "# # Print the best scores and the average score for each pipeline\n",
    "# print(best_scores1)\n",
    "# print(best_scores2)\n",
    "\n",
    "# # Get resulting classifier, pipeline 1\n",
    "# best_1 = grid_search1.best_estimator_\n",
    "# print(f'Best classifier: k={best_1.n_neighbors}')\n",
    "# best_n_neighbors.append(best_1.n_neighbors)\n",
    "\n",
    "# # Test the classifier on the test data, pipeline 1\n",
    "# probabilities = best_1.predict_proba(X_test)\n",
    "# scores_1 = probabilities[:, 1]\n",
    "\n",
    "# # Get the auc, pipeline 1\n",
    "# auc_1 = metrics.roc_auc_score(y_test, scores_1)\n",
    "# results_1.append({\n",
    "#     'auc': auc_1,\n",
    "#     'k': best_1.n_neighbors,\n",
    "#     'set': 'test'\n",
    "# })\n",
    "\n",
    "# # Create results dataframe and plot it, pipeline 1\n",
    "# results = pd.DataFrame(results_1)\n",
    "# seaborn.boxplot(y='auc', x='set', data=results_1)\n",
    "\n",
    "# optimal_n = int(np.median(best_n_neighbors))\n",
    "# print(f\"The optimal N={optimal_n}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
